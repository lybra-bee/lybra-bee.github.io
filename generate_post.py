#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import re
import time
import json
import random
import logging
import requests
import tempfile
from datetime import datetime
from pathlib import Path
from collections import deque

# ================== LOGGING ==================
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s | %(levelname)s | %(message)s"
)
log = logging.getLogger(__name__)

# ================== PATHS ==================
POSTS_DIR = Path("_posts")
IMAGES_DIR = Path("assets/images/posts")
MEMORY_FILE = Path("ai_topic_memory.json")

POSTS_DIR.mkdir(parents=True, exist_ok=True)
IMAGES_DIR.mkdir(parents=True, exist_ok=True)

# ================== ENV ==================
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
TELEGRAM_CHAT_ID = os.getenv("TELEGRAM_CHAT_ID")
GROQ_API_KEY = os.getenv("GROQ_API_KEY")

SITE_URL = "https://lybra-ai.ru"

if not GROQ_API_KEY:
    raise RuntimeError("‚ùå GROQ_API_KEY –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")

# ================== FALLBACK IMAGES ==================
FALLBACK_IMAGES = [
    "https://picsum.photos/1024/768?random=1",
    "https://picsum.photos/1024/768?random=2",
    "https://picsum.photos/1024/768?random=3",
]

# ================== TRANSLIT ==================
TRANSLIT_MAP = {
    '–∞':'a','–±':'b','–≤':'v','–≥':'g','–¥':'d','–µ':'e','—ë':'yo','–∂':'zh','–∑':'z','–∏':'i','–π':'y',
    '–∫':'k','–ª':'l','–º':'m','–Ω':'n','–æ':'o','–ø':'p','—Ä':'r','—Å':'s','—Ç':'t','—É':'u','—Ñ':'f',
    '—Ö':'kh','—Ü':'ts','—á':'ch','—à':'sh','—â':'shch','—ä':'','—ã':'y','—å':'','—ç':'e','—é':'yu','—è':'ya'
}

def translit(text):
    return ''.join(TRANSLIT_MAP.get(c, c) for c in text.lower())

# ================== MEMORY ==================
def load_memory():
    if MEMORY_FILE.exists():
        return json.loads(MEMORY_FILE.read_text(encoding="utf-8"))
    return {"topics": []}

def save_memory(mem):
    MEMORY_FILE.write_text(json.dumps(mem, ensure_ascii=False, indent=2), encoding="utf-8")

# ================== GOOGLE TRENDS TOPIC ==================
def fetch_google_trends_topic():
    log.info("üåç Fetching Google Trends topic")
    try:
        r = requests.get("https://trends.google.com/trends/hottrends", timeout=10)
        text = r.text.lower()
        candidates = re.findall(r"ai|machine learning|llm|chatgpt|openai|deep learning", text)
        if candidates:
            topic = random.choice(candidates)
            log.info(f"üî• Google Trends topic: {topic}")
            return f"{topic} practical AI"
    except Exception as e:
        log.warning(f"Google Trends error: {e}")
    return None

# ================== SMART TOPIC GENERATION ==================
def generate_topic():
    mem = load_memory()
    used = set(mem["topics"])

    base_prompt = """
–°–≥–µ–Ω–µ—Ä–∏—Ä—É–π –û–î–ù–£ –Ω–æ–≤—É—é –∞–∫—Ç—É–∞–ª—å–Ω—É—é —Ç–µ–º—É —Å—Ç–∞—Ç—å–∏ –ø—Ä–æ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ –∏ AI.

–ü—Ä–∞–≤–∏–ª–∞:
- –¢–æ–ª—å–∫–æ –ø—Ä–∞–∫—Ç–∏–∫–∞
- –î–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤ –∏ —ç–Ω—Ç—É–∑–∏–∞—Å—Ç–æ–≤
- –ë–µ–∑ —Ñ—É—Ç—É—Ä–∏–∑–º–∞
- –ë–µ–∑ –±–∏–∑–Ω–µ—Å–∞
- –ë–µ–∑ –ø–æ–≤—Ç–æ—Ä–æ–≤ –ø—Ä–æ—à–ª—ã—Ö —Ç–µ–º
- –ê–∫—Ç—É–∞–ª—å–Ω–æ –Ω–∞ 2025‚Äì2026
- –ü—Ä–∏–º–µ—Ä—ã: —É—Å–∫–æ—Ä–µ–Ω–∏–µ inference, fine-tuning, –∞–≥–µ–Ω—Ç—ã, open-source, –ª–æ–∫–∞–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏, multimodal

–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞:
–¢–ï–ú–ê: ...
"""

    url = "https://api.groq.com/openai/v1/chat/completions"
    headers = {"Authorization": f"Bearer {GROQ_API_KEY}"}

    for attempt in range(4):
        payload = {
            "model": "llama-3.3-70b-versatile",
            "messages": [{"role": "user", "content": base_prompt}],
            "temperature": 0.9,
            "max_tokens": 120
        }

        r = requests.post(url, headers=headers, json=payload, timeout=60)
        text = r.json()["choices"][0]["message"]["content"]

        match = re.search(r"–¢–ï–ú–ê:\s*(.+)", text)
        if match:
            topic = match.group(1).strip()
            if topic not in used:
                mem["topics"].append(topic)
                save_memory(mem)
                log.info(f"üß† Topic selected: {topic}")
                return topic

    fallback = "–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ AI –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤"
    log.warning(f"‚ö† Fallback topic: {fallback}")
    return fallback

# ================== TITLE ==================
def generate_title(topic):
    log.info(f"‚úçÔ∏è Generating title: {topic}")

    prompt = f"""
–°–¥–µ–ª–∞–π –ø—Ä–∏–∫–ª–∞–¥–Ω–æ–π –∑–∞–≥–æ–ª–æ–≤–æ–∫ —Å—Ç–∞—Ç—å–∏.

–¢–µ–º–∞: {topic}

–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:
- 8‚Äì14 —Å–ª–æ–≤
- –ü—Ä–∞–∫—Ç–∏–∫–∞
- –ë–µ–∑ —Ñ—É—Ç—É—Ä–∏–∑–º–∞
- –ë–µ–∑ –≤–æ–¥—ã
- –ö–æ–Ω–∫—Ä–µ—Ç–Ω–∞—è –ø–æ–ª—å–∑–∞

–§–æ—Ä–º–∞—Ç:
–ó–ê–ì–û–õ–û–í–û–ö: ...
"""

    url = "https://api.groq.com/openai/v1/chat/completions"
    headers = {"Authorization": f"Bearer {GROQ_API_KEY}"}

    for attempt in range(3):
        payload = {
            "model": "llama-3.3-70b-versatile",
            "messages": [{"role": "user", "content": prompt}],
            "temperature": 0.7,
            "max_tokens": 120
        }

        r = requests.post(url, headers=headers, json=payload, timeout=60)
        text = r.json()["choices"][0]["message"]["content"]
        log.info(f"Groq title raw: {text}")

        match = re.search(r"–ó–ê–ì–û–õ–û–í–û–ö:\s*(.+)", text)
        if match:
            title = match.group(1).strip()
            if 6 <= len(title.split()) <= 16:
                log.info(f"‚úÖ Title: {title}")
                return title

    fallback = "–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π –¥–ª—è —Ä–µ–∞–ª—å–Ω—ã—Ö –∑–∞–¥–∞—á —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∞"
    log.warning(f"‚ö† Title fallback: {fallback}")
    return fallback

# ================== OUTLINE ==================
def generate_outline(title):
    log.info("üìö Generating outline")

    prompt = f"""
–°–æ–∑–¥–∞–π –ø–ª–∞–Ω –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–π —Å—Ç–∞—Ç—å–∏:

"{title}"

–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:
- 6‚Äì9 —Ä–∞–∑–¥–µ–ª–æ–≤ ##
- –¢–æ–ª—å–∫–æ –ø—Ä–∞–∫—Ç–∏–∫–∞
- –ö–µ–π—Å—ã, –æ—à–∏–±–∫–∏, —Å–æ–≤–µ—Ç—ã
- –ë–µ–∑ —Ñ–∏–ª–æ—Å–æ—Ñ–∏–∏

–§–æ—Ä–º–∞—Ç: Markdown
"""

    url = "https://api.groq.com/openai/v1/chat/completions"
    headers = {"Authorization": f"Bearer {GROQ_API_KEY}"}

    payload = {
        "model": "llama-3.3-70b-versatile",
        "messages": [{"role": "user", "content": prompt}],
        "temperature": 0.4,
        "max_tokens": 800
    }

    r = requests.post(url, headers=headers, json=payload, timeout=60)
    outline = r.json()["choices"][0]["message"]["content"]
    log.info("‚úÖ Outline generated")
    return outline

# ================== SECTION ==================
def generate_section(title, outline, section):
    log.info(f"üß© Generating section: {section}")

    prompt = f"""
–°—Ç–∞—Ç—å—è: "{title}"
–†–∞–∑–¥–µ–ª: {section}

–ö–æ–Ω—Ç–µ–∫—Å—Ç –ø–ª–∞–Ω–∞:
{outline}

–ü—Ä–∞–≤–∏–ª–∞:
- 900‚Äì1500 –∑–Ω–∞–∫–æ–≤
- –ü—Ä–∞–∫—Ç–∏–∫–∞
- –ö–æ–º–∞–Ω–¥—ã, –ø—Ä–∏–º–µ—Ä—ã, –∫–æ–¥
- –û—à–∏–±–∫–∏ –∏ —Å–æ–≤–µ—Ç—ã
- –ë–µ–∑ –≤–æ–¥—ã
"""

    url = "https://api.groq.com/openai/v1/chat/completions"
    headers = {"Authorization": f"Bearer {GROQ_API_KEY}"}

    for attempt in range(3):
        payload = {
            "model": "llama-3.3-70b-versatile",
            "messages": [{"role": "user", "content": prompt}],
            "temperature": 0.6,
            "max_tokens": 800
        }

        r = requests.post(url, headers=headers, json=payload, timeout=60)

        if r.status_code == 429:
            log.warning("‚è≥ Groq rate limit ‚Äî waiting")
            time.sleep(5)
            continue

        r.raise_for_status()
        text = r.json()["choices"][0]["message"]["content"].strip()

        if len(text) > 600:
            return text

    return "‚ö† –†–∞–∑–¥–µ–ª –Ω–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å, –ø—Ä–æ–ø—É—â–µ–Ω."

# ================== BODY ==================
def generate_body(title):
    outline = generate_outline(title)
    headers = [re.sub(r'^##\s*', '', l) for l in outline.splitlines() if l.startswith("##")]

    body = f"# {title}\n\n"
    total = 0

    for h in headers:
        section_text = generate_section(title, outline, h)
        body += f"## {h}\n\n{section_text}\n\n"
        total += len(section_text)

    log.info(f"üìè Body length: {total}")

    if total < 6000:
        raise RuntimeError("‚ùå Article too short")

    return body

# ================== IMAGE (UNCHANGED ‚Äî YOUR HORDE) ==================
def generate_image_horde(title):
    styles = [
        "realistic ai lab",
        "developer working with AI",
        "neural network visualization",
        "machine learning workflow",
        "coding with AI assistant"
    ]
    style = random.choice(styles)

    prompt = f"{title}, {style}, ultra realistic, professional photography, 8k"

    negative_prompt = "girl, woman, cartoon, blurry, watermark"

    url_async = "https://stablehorde.net/api/v2/generate/async"
    payload = {
        "prompt": prompt + " ### " + negative_prompt,
        "models": ["Juggernaut XL", "Realistic Vision V5.1", "SDXL 1.0"],
        "params": {"width": 768, "height": 512, "steps": 30, "cfg_scale": 7.5},
        "nsfw": False
    }

    headers = {"apikey": "0000000000", "Client-Agent": "LybraBlogBot:3.0"}

    try:
        r = requests.post(url_async, json=payload, headers=headers, timeout=60)
        if not r.ok:
            return None

        job_id = r.json().get("id")
        if not job_id:
            return None

        check_url = f"https://stablehorde.net/api/v2/generate/check/{job_id}"
        status_url = f"https://stablehorde.net/api/v2/generate/status/{job_id}"

        for _ in range(36):
            time.sleep(10)
            check = requests.get(check_url, headers=headers).json()
            if check.get("done"):
                final = requests.get(status_url, headers=headers).json()
                if final.get("generations"):
                    img_url = final["generations"][0]["img"]
                    img_data = requests.get(img_url).content
                    path = IMAGES_DIR / f"horde-{int(time.time())}.jpg"
                    path.write_bytes(img_data)
                    log.info(f"üñº Image saved: {path}")
                    return str(path)
    except Exception as e:
        log.warning(f"Horde error: {e}")

    return None

def generate_image(title):
    img = generate_image_horde(title)
    if img and os.path.exists(img):
        return img
    fallback = random.choice(FALLBACK_IMAGES)
    log.warning(f"‚ö† Using fallback image: {fallback}")
    return fallback

# ================== SAVE POST ==================
def save_post(title, body, image):
    date = datetime.now()
    slug = re.sub(r'[^a-z0-9-]+', '-', translit(title)).strip('-')[:80]
    file = POSTS_DIR / f"{date:%Y-%m-%d}-{slug}.md"

    front = f"""---
title: "{title}"
date: {date:%Y-%m-%d 00:00:00 -0000}
layout: post
categories: ai
image: {image if image.startswith('http') else '/assets/images/posts/' + Path(image).name}
---

"""

    file.write_text(front + body, encoding="utf-8")
    log.info(f"üìù Post saved: {file}")
    return SITE_URL

# ================== CLEAN OLD POSTS ==================
def cleanup_old_posts(limit=70):
    posts = sorted(POSTS_DIR.glob("*.md"), reverse=True)
    if len(posts) > limit:
        for p in posts[limit:]:
            log.info(f"üßπ Removing old post: {p}")
            p.unlink()

# ================== TELEGRAM ==================
def send_to_telegram(title, teaser, image):
    if not TELEGRAM_BOT_TOKEN or not TELEGRAM_CHAT_ID:
        log.warning("Telegram disabled")
        return

    caption = f"<b>{title}</b>\n\n{teaser}\n\nüëâ {SITE_URL}"

    if image.startswith("http"):
        img = requests.get(image).content
        f = tempfile.NamedTemporaryFile(delete=False)
        f.write(img)
        f.close()
        image = f.name

    with open(image, "rb") as p:
        requests.post(
            f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendPhoto",
            data={"chat_id": TELEGRAM_CHAT_ID, "caption": caption, "parse_mode": "HTML"},
            files={"photo": p},
        )

    log.info("üì¨ Telegram sent")

# ================== MAIN ==================
def main():
    log.info("=== START ===")

    topic = fetch_google_trends_topic() or generate_topic()
    log.info(f"üéØ Topic: {topic}")

    title = generate_title(topic)
    body = generate_body(title)
    image = generate_image(title)

    save_post(title, body, image)

    teaser = " ".join(body.split()[:45]) + "..."
    send_to_telegram(title, teaser, image)

    cleanup_old_posts()

    log.info("=== DONE ===")

if __name__ == "__main__":
    main()
