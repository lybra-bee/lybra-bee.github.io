#!/usr/bin/env python3
"""
–ê–≤—Ç–æ–Ω–æ–º–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å—Ç–∞—Ç–µ–π –æ–± –ò–ò 2025-2026
- –°–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ –æ–±–Ω–æ–≤–ª—è–µ—Ç —Ç—Ä–µ–Ω–¥—ã
- –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ä—É—Å—Å–∫—É—é —Å—Ç–∞—Ç—å—é —Å —Ü–∏—Ñ—Ä–∞–º–∏ –∏ —Ç–∞–±–ª–∏—Ü–∞–º–∏
- –°–æ–∑–¥–∞–µ—Ç —Ñ–æ—Ç–æ—Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (PNG)
- –ü—É–±–ª–∏–∫—É–µ—Ç –ø–æ—Å—Ç –¥–ª—è Jekyll
- –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Ç–∏–∑–µ—Ä –∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ Telegram
- –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –¥–ª—è GitHub Actions
"""

import datetime
import random
import os
import re
import json
import time
import glob
from typing import Dict, List

import requests
import yaml
from groq import Groq

LOG_FILE = "generation.log"

def log(msg: str):
    ts = datetime.datetime.utcnow().isoformat()
    with open(LOG_FILE, "a", encoding="utf-8") as f:
        f.write(f"[{ts}] {msg}\n")
    print(msg)

# ---------- –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ----------
EMBEDDED_TRENDS_FILE = "trends_cache.json"
TRENDS_UPDATE_INTERVAL = 86400
BASE_URL = "https://lybra-ai.ru"

# ---------- MARKDOWN NORMALIZER ----------
def normalize_markdown(md: str) -> str:
    if not md:
        return md
    md = re.sub(r"<[^>]+>", "", md)
    md = re.sub(r"\n{3,}", "\n\n", md)
    return md.strip() + "\n"

# ---------- TRENDS ----------
EMBEDDED_TRENDS = [
    {"id": "quantum_2025", "news": "New quantum processors reach practical speedups in optimization tasks", "keywords": ["quantum", "processors"], "category": "hardware"},
    {"id": "agentic_ai_2025", "news": "Agentic AI systems coordinate multiple models for enterprise workflows", "keywords": ["agentic ai", "automation"], "category": "software"},
    {"id": "ai_efficiency", "news": "Inference costs drop by 200x with sparse and low-rank models", "keywords": ["efficiency", "inference"], "category": "optimization"},
]

def load_trends() -> List[Dict]:
    try:
        if os.path.exists(EMBEDDED_TRENDS_FILE):
            with open(EMBEDDED_TRENDS_FILE, encoding="utf-8") as f:
                cache = json.load(f)
                if time.time() - cache.get("last_update", 0) < TRENDS_UPDATE_INTERVAL:
                    log("‚úÖ –¢—Ä–µ–Ω–¥—ã –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏–∑ –∫—ç—à–∞")
                    return cache["trends"]
    except Exception as e:
        log(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∫—ç—à–∞: {e}")
    return EMBEDDED_TRENDS

# ---------- –ê–ù–¢–ò–ü–û–õ–ò–¢–ò–ö–ê ----------
POLITICAL_RE = re.compile(
    r"\b(–≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤|–∑–∞–∫–æ–Ω|—Ä–µ–≥—É–ª—è—Ç–æ—Ä|–º–∏–Ω–∏—Å—Ç—Ä|–ø—Ä–µ–∑–∏–¥–µ–Ω—Ç|—Å—Ç—Ä–∞–Ω–∞|—Å–∞–Ω–∫—Ü)\b",
    re.I
)

def is_political(text: str) -> bool:
    return bool(POLITICAL_RE.search(text))

# ---------- –ó–ê–ì–û–õ–û–í–û–ö ----------
def generate_title(client: Groq, trend: Dict, article_type: str) -> str:
    prompt = (
        f"–°–æ–∑–¥–∞–π –û–î–ò–ù —Ü–µ–ø–ª—è—é—â–∏–π –∑–∞–≥–æ–ª–æ–≤–æ–∫ (5‚Äì12 —Å–ª–æ–≤).\n"
        f"–¢–µ–º–∞: {trend['news']}.\n"
        "–¢–æ–ª—å–∫–æ –ò–ò –∏ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏. –ë–µ–∑ –ø–æ–ª–∏—Ç–∏–∫–∏.\n"
        "–¢–æ–ª—å–∫–æ –∑–∞–≥–æ–ª–æ–≤–æ–∫."
    )
    resp = client.chat.completions.create(
        messages=[
            {"role": "system", "content": "–†—É—Å—Å–∫–∏–π tech-—Ä–µ–¥–∞–∫—Ç–æ—Ä"},
            {"role": "user", "content": prompt}
        ],
        model="llama-3.1-8b-instant",
        temperature=1.0,
        max_tokens=40
    )
    title = resp.choices[0].message.content.strip()
    log(f"üì∞ –ó–∞–≥–æ–ª–æ–≤–æ–∫: {title}")
    return re.sub(r"[^\w\s-]", "", title)[:80]

# ---------- –°–¢–ê–¢–¨–Ø ----------
def generate_article(client: Groq, trend: Dict, article_type: str) -> str:
    system_prompt = (
        "–¢—ã —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –∂—É—Ä–Ω–∞–ª–∏—Å—Ç –ø–æ –ò–ò.\n"
        "–°–¢–†–û–ì–û –∑–∞–ø—Ä–µ—â–µ–Ω–∞ –ø–æ–ª–∏—Ç–∏–∫–∞, –∑–∞–∫–æ–Ω—ã, —Å—Ç—Ä–∞–Ω—ã.\n"
        "–§–æ–∫—É—Å: —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏, —Ü–∏—Ñ—Ä—ã, –ø—Ä–∞–∫—Ç–∏–∫–∞."
    )
    user_prompt = (
        f"–ù–∞–ø–∏—à–∏ —Å—Ç–∞—Ç—å—é —Ç–∏–ø–∞ '{article_type}' (1500‚Äì2500 —Å–ª–æ–≤).\n"
        f"–¢–µ–º–∞: {trend['news']}\n"
        "Markdown, —Ç–∞–±–ª–∏—Ü—ã, –º–µ—Ç—Ä–∏–∫–∏."
    )

    resp = client.chat.completions.create(
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ],
        model="llama-3.3-70b-versatile",
        temperature=0.8,
        max_tokens=4000
    )
    content = resp.choices[0].message.content
    if is_political(content):
        raise ValueError("–ü–æ–ª–∏—Ç–∏–∫–∞ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞")
    log("üìÑ –°—Ç–∞—Ç—å—è —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–∞")
    return normalize_markdown(content)

# ---------- PNG PLACEHOLDER ----------
def generate_placeholder_png(path: str):
    from PIL import Image, ImageDraw
    img = Image.new("RGB", (1280, 720), (18, 22, 28))
    draw = ImageDraw.Draw(img)
    draw.text((640, 360), "AI ‚Ä¢ High Tech ‚Ä¢ 2025", fill=(200, 200, 200), anchor="mm")
    img.save(path, "PNG", optimize=True)

# ---------- –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–ï ----------
def generate_image(title: str, trend: Dict, post_num: int) -> bool:
    path = f"{assets_dir}/post-{post_num}.png"
    prompt = (
        f"Ultra realistic photo of {title}. {trend['news']}. "
        "Photorealistic, cinematic, real world, no text, no charts."
    )

    for name, url, headers in [
        ("CLIPDROP", "https://clipdrop-api.co/text-to-image/v1",
         {"x-api-key": os.getenv("CLIPDROP_API_KEY")}),
        ("HF", "https://api-inference.huggingface.co/models/stabilityai/sdxl-turbo",
         {"Authorization": f"Bearer {os.getenv('HF_API_TOKEN')}"})
    ]:
        if not list(headers.values())[0]:
            continue
        try:
            r = requests.post(url,
                headers=headers,
                files={"prompt": (None, prompt)} if "clipdrop" in url else None,
                json={"inputs": prompt} if "huggingface" in url else None,
                timeout=90)
            if r.status_code == 200 and r.headers.get("content-type","").startswith("image"):
                open(path, "wb").write(r.content)
                log(f"üñº –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–æ–∑–¥–∞–Ω–æ: {name}")
                return True
        except Exception as e:
            log(f"‚ùå {name}: {e}")

    generate_placeholder_png(path)
    log("üü® –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∞ PNG-–∑–∞–≥–ª—É—à–∫–∞")
    return True

# ---------- MAIN ----------
def main() -> bool:
    client = Groq(api_key=os.getenv("GROQ_API_KEY"))
    trends = load_trends()
    trend = random.choice(trends)
    article_type = random.choice(["–û–±–∑–æ—Ä", "–ú–∞—Å—Ç–µ—Ä-–∫–ª–∞—Å—Å", "–ê–Ω–∞–ª–∏—Ç–∏–∫–∞"])

    title = generate_title(client, trend, article_type)
    content = generate_article(client, trend, article_type)
    generate_image(title, trend, post_num)

    front_matter = {
        "title": title,
        "date": f"{today} 00:00:00 +0000",
        "layout": "post",
        "image": f"/assets/images/posts/post-{post_num}.png",
        "description": trend["news"],
        "tags": ["–ò–ò", "—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏"] + trend["keywords"],
    }

    slug = re.sub(r"[^\w-]", "-", title.lower())[:50]
    filename = f"{posts_dir}/{today}-{slug}.md"

    with open(filename, "w", encoding="utf-8") as f:
        f.write("---\n")
        yaml.dump(front_matter, f, allow_unicode=True)
        f.write("---\n\n")
        f.write(content)

    log(f"‚úÖ –ü–æ—Å—Ç –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω: {filename}")
    return True

# ---------- INIT ----------
if __name__ == "__main__":
    posts_dir = "_posts"
    assets_dir = "assets/images/posts"
    os.makedirs(posts_dir, exist_ok=True)
    os.makedirs(assets_dir, exist_ok=True)

    post_num = len(glob.glob(f"{assets_dir}/*.png")) + 1
    today = datetime.date.today()

    success = main()
    raise SystemExit(0 if success else 1)
