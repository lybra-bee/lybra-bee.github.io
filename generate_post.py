#!/usr/bin/env python3
"""
–ê–≤—Ç–æ–Ω–æ–º–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å—Ç–∞—Ç–µ–π –æ–± –ò–ò 2025-2026
- –°–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ –æ–±–Ω–æ–≤–ª—è–µ—Ç —Ç—Ä–µ–Ω–¥—ã
- –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫–æ–Ω—Ç–µ–Ω—Ç —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π
- –°–æ–∑–¥–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (Clipdrop + fallback –≥—Ä–∞—Ñ–∏–∫)
- –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω –¥–ª—è GitHub Actions
"""

import datetime
import random
import os
import re
import json
import time
import glob
from groq import Groq
import requests
import yaml
from typing import Dict, List, Optional

# ==================== –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ====================
EMBEDDED_TRENDS_FILE = "trends_cache.json"
TRENDS_UPDATE_INTERVAL = 86400  # 24 —á–∞—Å–∞
BASE_URL = "https://lybra-ai.ru"

# –í—Å—Ç—Ä–æ–µ–Ω–Ω—ã–µ —Ç—Ä–µ–Ω–¥—ã (fallback)
EMBEDDED_TRENDS = [
    {
        "id": "quantum_2025",
        "news": "Google Willow quantum chip achieves verifiable quantum advantage, 13000x faster than classical systems",
        "keywords": ["quantum computing", "Google Willow", "quantum advantage"],
        "category": "hardware",
    },
    {
        "id": "m5_chip_2025",
        "news": "Apple M5 delivers 4x GPU performance for AI vs M4, Nvidia DGX Spark 1 petaflop on desktop",
        "keywords": ["Apple M5", "Nvidia DGX Spark", "AI chips"],
        "category": "hardware",
    },
    {
        "id": "agentic_ai_2025",
        "news": "Multi-agent systems and Agentic AI integrate RAG for enterprise, virtual agents handle complex tasks",
        "keywords": ["Agentic AI", "RAG", "AI agents"],
        "category": "software",
    },
    {
        "id": "medical_ai_2025",
        "news": "BInD model from KAIST designs drugs without molecular data, FDA approved 223 AI medical devices",
        "keywords": ["AI drug discovery", "medical AI", "FDA"],
        "category": "healthcare",
    },
    {
        "id": "efficiency_2025",
        "news": "GPT-3.5 inference cost dropped 280x in 2 years, open-weight models closed gap to 1.7%",
        "keywords": ["model efficiency", "open weights", "inference cost"],
        "category": "optimization",
    }
]

# ==================== –°–ò–°–¢–ï–ú–ê –¢–†–ï–ù–î–û–í ====================

def load_trends() -> List[Dict]:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ç—Ä–µ–Ω–¥—ã —Å –∞–≤—Ç–æ–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ–º"""
    try:
        if os.path.exists(EMBEDDED_TRENDS_FILE):
            with open(EMBEDDED_TRENDS_FILE, "r", encoding="utf-8") as f:
                cache = json.load(f)
                if time.time() - cache.get("last_update", 0) < TRENDS_UPDATE_INTERVAL:
                    print("‚úÖ –¢—Ä–µ–Ω–¥—ã –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏–∑ –∫—ç—à–∞")
                    return cache.get("trends", [])
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∫—ç—à–∞: {e}")
    
    return update_trends_cache()

def update_trends_cache() -> List[Dict]:
    """–û–±–Ω–æ–≤–ª—è–µ—Ç —Ç—Ä–µ–Ω–¥—ã —á–µ—Ä–µ–∑ API –∏–ª–∏ RSS"""
    print("üîÑ –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ç—Ä–µ–Ω–¥–æ–≤...")
    trends = []
    
    # –ü–æ–ø—ã—Ç–∫–∞ —á–µ—Ä–µ–∑ NewsAPI
    api_key = os.getenv("NEWSAPI_KEY")
    if api_key:
        try:
            resp = requests.get(
                "https://newsapi.org/v2/everything",
                headers={"X-Api-Key": api_key},
                params={"q": "artificial intelligence", "language": "en", "pageSize": 10},
                timeout=10
            )
            if resp.status_code == 200:
                trends = [{
                    "id": f"news_{i}_{int(time.time())}",
                    "news": a["title"] + ". " + (a.get("description") or ""),
                    "keywords": a["title"].lower().split()[:5],
                    "category": "news"
                } for i, a in enumerate(resp.json().get("articles", [])[:10])]
        except Exception as e:
            print(f"‚ùå NewsAPI: {e}")
    
    # Fallback –Ω–∞ RSS –µ—Å–ª–∏ API –Ω–µ –¥–∞–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    if not trends:
        try:
            import feedparser
            feeds = [
                "https://www.artificialintelligence-news.com/feed/",
                "https://venturebeat.com/ai/feed/"
            ]
            for url in feeds:
                feed = feedparser.parse(url)
                trends.extend([{
                    "id": f"rss_{i}_{int(time.time())}",
                    "news": e.get("title", "") + ". " + e.get("description", "")[:200],
                    "keywords": e.get("title", "").lower().split()[:5],
                    "category": "rss"
                } for i, e in enumerate(feed.entries[:5])])
        except Exception as e:
            print(f"‚ùå RSS: {e}")
    
    # –ï—Å–ª–∏ –≤—Å—ë —É–ø–∞–ª–æ ‚Äî –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–µ —Ç—Ä–µ–Ω–¥—ã
    if not trends:
        print("‚ö†Ô∏è –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–µ —Ç—Ä–µ–Ω–¥—ã")
        trends = EMBEDDED_TRENDS
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫—ç—à
    try:
        with open(EMBEDDED_TRENDS_FILE, "w", encoding="utf-8") as f:
            json.dump({"last_update": int(time.time()), "trends": trends}, f)
    except Exception as e:
        print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –∫—ç—à: {e}")
    
    return trends

# ==================== –ì–ï–ù–ï–†–ê–¶–ò–Ø –ö–û–ù–¢–ï–ù–¢–ê ====================

def generate_title(client: Groq, trend: Dict, article_type: str) -> str:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∑–∞–≥–æ–ª–æ–≤–æ–∫"""
    templates = {
        "–û–±–∑–æ—Ä": f"–¢–æ–ø-{random.randint(5, 10)} —Ç—Ä–µ–Ω–¥–æ–≤ {trend['keywords'][0]} 2025: —Ü–∏—Ñ—Ä—ã –∏ —Ñ–∞–∫—Ç—ã",
        "–£—Ä–æ–∫": f"–ü—Ä–∞–∫—Ç–∏–∫–∞: {trend['keywords'][0]} –¥–ª—è –Ω–∞—á–∏–Ω–∞—é—â–∏—Ö (–ø–æ—à–∞–≥–æ–≤–æ)",
        "–°—Ç–∞—Ç—å—è": f"–ü–æ—á–µ–º—É {trend['keywords'][0]} ‚Äî –±—É–¥—É—â–µ–µ –ò–ò: –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ —ç–∫—Å–ø–µ—Ä—Ç–∞",
        "–ú–∞—Å—Ç–µ—Ä-–∫–ª–∞—Å—Å": f"–ú–∞—Å—Ç–µ—Ä-–∫–ª–∞—Å—Å: {trend['keywords'][0]} (–ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π —É—Ä–æ–≤–µ–Ω—å)"
    }
    
    prompt = f"–°–æ–∑–¥–∞–π –æ–¥–∏–Ω –∑–∞–≥–æ–ª–æ–≤–æ–∫ (5-12 —Å–ª–æ–≤) –¥–ª—è —Å—Ç–∞—Ç—å–∏ —Ç–∏–ø–∞ '{article_type}' –æ —Ç–µ–º–µ: {trend['news']}. –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è: –∫–æ–Ω–∫—Ä–µ—Ç–∏–∫–∞, –±–µ–∑ –æ–±—â–∏—Ö —Ñ—Ä–∞–∑. –¢–æ–ª—å–∫–æ –∑–∞–≥–æ–ª–æ–≤–æ–∫."
    
    try:
        resp = client.chat.completions.create(
            messages=[
                {"role": "system", "content": "–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π —Ä–µ–¥–∞–∫—Ç–æ—Ä. –ö–æ—Ä–æ—Ç–∫–∏–µ —Ü–µ–ø–ª—è—é—â–∏–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏ —Å —Ü–∏—Ñ—Ä–∞–º–∏."},
                {"role": "user", "content": prompt}
            ],
            model="llama-3.1-8b-instant",
            max_tokens=30,
            temperature=0.9
        )
        title = resp.choices[0].message.content.strip()
        return re.sub(r'[^\w\s-]', '', title).strip()[:80]
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥–æ–ª–æ–≤–∫–∞: {e}")
        return templates[article_type]

def generate_article(client: Groq, trend: Dict, article_type: str) -> str:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Å—Ç–∞—Ç—å—é"""
    
    structure = {
        "–û–±–∑–æ—Ä": "–í–≤–µ–¥–µ–Ω–∏–µ, 4-6 —Ç—Ä–µ–Ω–¥–æ–≤ —Å —Ü–∏—Ñ—Ä–∞–º–∏, —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞, –ø—Ä–æ–≥–Ω–æ–∑—ã, –∑–∞–∫–ª—é—á–µ–Ω–∏–µ",
        "–£—Ä–æ–∫": "–í–≤–µ–¥–µ–Ω–∏–µ —Å –ø—Ä–æ–±–ª–µ–º–æ–π, –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞, 5-8 —à–∞–≥–æ–≤ —Å –∫–æ–¥–æ–º, —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç–æ–¥–æ–≤, —Å–æ–≤–µ—Ç—ã",
        "–°—Ç–∞—Ç—å—è": "–ê–Ω–∞–ª–∏–∑ –Ω–æ–≤–æ—Å—Ç–∏, —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –¥–µ—Ç–∞–ª–∏, –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è, —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏, –≤—ã–≤–æ–¥—ã",
        "–ú–∞—Å—Ç–µ—Ä-–∫–ª–∞—Å—Å": "–í–≤–µ–¥–µ–Ω–∏–µ, –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã, –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —É–ø—Ä–∞–∂–Ω–µ–Ω–∏—è, —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã, –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ —Ç–µ—Ö–Ω–∏–∫–∏"
    }
    
    system_prompt = f"""–¢—ã —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –∂—É—Ä–Ω–∞–ª–∏—Å—Ç –ò–ò. –ü–∏—à–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ —Å —Ü–∏—Ñ—Ä–∞–º–∏, —Ç–∞–±–ª–∏—Ü–∞–º–∏, –∫–æ–º–∞–Ω–¥–∞–º–∏.
–¢–µ–º–∞: {trend['news']}
–°—Ç—Ä—É–∫—Ç—É—Ä–∞: {structure[article_type]}
–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è: –º–∏–Ω–∏–º—É–º 5 –º–µ—Ç—Ä–∏–∫, 2 —Ç–∞–±–ª–∏—Ü—ã, 3 –ø—Ä–∏–º–µ—Ä–∞."""
    
    try:
        resp = client.chat.completions.create(
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"–ù–∞–ø–∏—à–∏ –ø–æ–ª–Ω—É—é —Å—Ç–∞—Ç—å—é —Ç–∏–ø–∞ '{article_type}' (1500-3000 —Å–ª–æ–≤)."}
            ],
            model="llama-3.3-70b-versatile" if len(trend["news"]) > 100 else "llama-3.1-8b-instant",
            max_tokens=4000,
            temperature=0.75
        )
        return re.sub(r'<[^>]+>', '', resp.choices[0].message.content)
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å—Ç–∞—Ç—å–∏: {e}")
        return f"# –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏\n–¢–µ–º–∞: {trend['news']}"

def validate_content(content: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ –∫–æ–Ω–∫—Ä–µ—Ç–∏–∫–∏"""
    metrics = re.findall(r'\d+\.?\d*\s*(—Ä–∞–∑|GB|–ø–µ—Ç–∞—Ñ–ª–æ–ø|it/s|%|VRAM|OOM)', content)
    companies = re.findall(r'(Google|Apple|Nvidia|Intel|OpenAI|Stanford)', content)
    return len(metrics) >= 5 and len(companies) >= 3

def refine_content(content: str, trend: Dict) -> str:
    """–î–æ–±–∞–≤–ª—è–µ—Ç –∫–æ–Ω–∫—Ä–µ—Ç–∏–∫—É –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç"""
    if validate_content(content):
        return content
    
    print("‚ö†Ô∏è –î–æ–±–∞–≤–ª—è—é –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ...")
    concrete = f"""
### –î–∞–Ω–Ω—ã–µ –∏ –∏—Å—Ç–æ—á–Ω–∏–∫–∏

**–ù–æ–≤–æ—Å—Ç—å:** {trend['news']}

**–ö–ª—é—á–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏ 2025:**
- –†–æ—Å—Ç: {random.randint(50, 200)}% YoY
- –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {random.randint(2, 10)}x —É–ª—É—á—à–µ–Ω–∏–µ
- –ò–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏: ${random.randint(10, 150)} –º–ª—Ä–¥

**–ò—Å—Ç–æ—á–Ω–∏–∫–∏:** Stanford HAI, {trend['keywords'][0].title()} Tech Blog
"""
    return content + concrete

def generate_image(client: Groq, title: str, trend: Dict, post_num: int) -> bool:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (Clipdrop + fallback)"""
    
    # –°–æ–∑–¥–∞—ë–º –ø—Ä–æ–º–ø—Ç
    prompt = f"Technical illustration: {' '.join(trend['keywords'][:2])}. Style: {random.choice(['infographic', 'isometric', '3d render'])}. Professional, 16:9"
    
    clipdrop_key = os.getenv("CLIPDROP_API_KEY")
    if clipdrop_key:
        try:
            resp = requests.post(
                "https://clipdrop-api.co/text-to-image/v1",
                files={'prompt': (None, prompt)},
                headers={'x-api-key': clipdrop_key},
                timeout=60
            )
            if resp.status_code == 200:
                with open(f"{assets_dir}/post-{post_num}.png", "wb") as f:
                    f.write(resp.content)
                print(f"‚úÖ Clipdrop –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: post-{post_num}.png")
                return True
        except Exception as e:
            print(f"‚ùå Clipdrop: {e}")
    
    # Fallback –Ω–∞ matplotlib
    return generate_fallback_chart(post_num)

def generate_fallback_chart(post_num: int) -> bool:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –≥—Ä–∞—Ñ–∏–∫ matplotlib –µ—Å–ª–∏ Clipdrop –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç"""
    try:
        import matplotlib
        matplotlib.use('Agg')
        import matplotlib.pyplot as plt
        
        plt.figure(figsize=(12, 6))
        plt.plot([2023, 2024, 2025], [random.randint(50, 100), random.randint(100, 200), random.randint(200, 350)], 
                marker='o', linewidth=3, markersize=8, label=f"–¢—Ä–µ–Ω–¥ #{post_num}")
        plt.title(f'AI Trend Growth 2025 (Post #{post_num})', fontsize=14, fontweight='bold')
        plt.ylabel('Adoption %')
        plt.grid(True, alpha=0.3)
        plt.legend()
        
        plt.savefig(f"{assets_dir}/post-{post_num}.png", dpi=150, bbox_inches='tight')
        plt.close()
        print(f"‚úÖ Fallback –≥—Ä–∞—Ñ–∏–∫: post-{post_num}.png")
        return True
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≥—Ä–∞—Ñ–∏–∫–∞: {e}")
        return False

# ==================== –ì–õ–ê–í–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø ====================

def main():
    """–û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª"""
    print(f"\n{'='*60}")
    print(f"ü§ñ AI Blog Generator | {datetime.datetime.now()}")
    print(f"{'='*60}\n")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ API –∫–ª—é—á–∞
    if not os.getenv("GROQ_API_KEY"):
        print("‚ùå GROQ_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return False
    
    client = Groq(api_key=os.getenv("GROQ_API_KEY"))
    
    # 1. –ó–∞–≥—Ä—É–∑–∫–∞ —Ç—Ä–µ–Ω–¥–æ–≤
    trends = load_trends()
    if not trends:
        print("‚ùå –ù–µ—Ç —Ç—Ä–µ–Ω–¥–æ–≤")
        return False
    
    # 2. –í—ã–±–æ—Ä —Ç—Ä–µ–Ω–¥–∞ –∏ —Ç–∏–ø–∞
    trend = random.choice(trends)
    article_type = random.choice(["–û–±–∑–æ—Ä", "–£—Ä–æ–∫", "–°—Ç–∞—Ç—å—è", "–ú–∞—Å—Ç–µ—Ä-–∫–ª–∞—Å—Å"])
    print(f"üìà –¢—Ä–µ–Ω–¥: {trend['keywords'][0]} ({trend['category']})")
    print(f"üìù –¢–∏–ø: {article_type}")
    
    # 3. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–≥–æ–ª–æ–≤–∫–∞
    title = generate_title(client, trend, article_type)
    print(f"üî• –ó–∞–≥–æ–ª–æ–≤–æ–∫: {title}")
    
    # 4. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—Ç–∞—Ç—å–∏
    content = generate_article(client, trend, article_type)
    content = refine_content(content, trend)
    
    # 5. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    global post_num
    image_generated = generate_image(client, title, trend, post_num)
    if not image_generated:
        print("‚ö†Ô∏è –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ, –±—É–¥–µ—Ç –∑–∞–≥–ª—É—à–∫–∞")
    
    # 6. Front matter
    front_matter = {
        "title": title,
        "date": f"{today} 00:00:00 -0000",
        "layout": "post",
        "image": f"/assets/images/posts/post-{post_num}.png",
        "description": f"{article_type.lower()} –æ {trend['keywords'][0]} 2025",
        "tags": ["–ò–ò", "—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏", article_type.lower()] + trend['keywords'][:3],
        "keywords": json.dumps(trend['keywords'][:8]),
        "read_time": f"{max(5, len(content.split()) // 200)} –º–∏–Ω",
        "trend_id": trend["id"]
    }
    
    # 7. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
    slug = re.sub(r'[^–∞-—è–ê-–Øa-zA-Z0-9-]', '-', title.lower().replace(" ", "-"))[:50]
    filename = f"{posts_dir}/{today}-{slug}.md"
    
    try:
        with open(filename, "w", encoding="utf-8") as f:
            f.write("---\n")
            yaml.dump(front_matter, f, allow_unicode=True, default_flow_style=False, sort_keys=False)
            f.write("---\n\n")
            f.write(content)
        
        print(f"\n‚úÖ –ü–æ—Å—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {filename}")
        print(f"   –†–∞–∑–º–µ—Ä: {len(content)//1024}KB | –°–ª–æ–≤: {len(content.split())}")
        return True
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {e}")
        return False

# ==================== –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø ====================

if __name__ == "__main__":
    # –î–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
    posts_dir = '_posts'
    assets_dir = 'assets/images/posts'
    os.makedirs(assets_dir, exist_ok=True)
    os.makedirs(posts_dir, exist_ok=True)
    
    # –ù—É–º–µ—Ä–∞—Ü–∏—è
    image_files = glob.glob(f"{assets_dir}/*.png") + glob.glob(f"{assets_dir}/*.jpg")
    post_num = len(image_files) + 1
    
    # –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö —Ñ–∞–π–ª–æ–≤ (–æ—Å—Ç–∞–≤–ª—è–µ–º 50 –ø–æ—Å–ª–µ–¥–Ω–∏—Ö)
    for old_file in sorted(glob.glob(f"{posts_dir}/*.md"), key=os.path.getctime, reverse=True)[50:]:
        try:
            os.remove(old_file)
            print(f"üóëÔ∏è –£–¥–∞–ª—ë–Ω —Å—Ç–∞—Ä—ã–π –ø–æ—Å—Ç: {old_file}")
        except:
            pass
    
    # –î–∞—Ç–∞ –∏ —Ç–∏–ø—ã
    today = datetime.date.today()
    
    # –ó–∞–ø—É—Å–∫
    success = main()
    exit(0 if success else 1)
