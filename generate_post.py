#!/usr/bin/env python3
"""
–ê–≤—Ç–æ–Ω–æ–º–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å—Ç–∞—Ç–µ–π –æ–± –ò–ò 2025-2026
- –ñ—ë—Å—Ç–∫–æ –∑–∞–ø—Ä–µ—â–µ–Ω–∞ –ø–æ–ª–∏—Ç–∏–∫–∞
- –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—Ç–∞—Ç—å–∏ –∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
- –ü—É–±–ª–∏–∫–∞—Ü–∏—è –≤ Telegram
- –ü–æ–ª–Ω—ã–µ –ª–æ–≥–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
"""

import datetime
import random
import os
import re
import json
import time
import glob
import logging
from typing import Dict, List

import requests
import yaml
from groq import Groq

# ---------- –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è ----------
logging.basicConfig(
    filename="generation.log",
    filemode="w",
    level=logging.INFO,
    format="%(asctime)s | %(levelname)s | %(message)s"
)
logger = logging.getLogger()

# ---------- –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è ----------
EMBEDDED_TRENDS_FILE = "trends_cache.json"
TRENDS_UPDATE_INTERVAL = 86400  # 24 —á–∞—Å–∞
BASE_URL = "https://lybra-ai.ru"

EMBEDDED_TRENDS = [
    {"id": "quantum_2025", "news": "Google Willow quantum chip achieves verifiable quantum advantage, 13000x faster", "keywords": ["quantum computing", "Google Willow"], "category": "hardware"},
    {"id": "m5_chip_2025", "news": "Apple M5 delivers 4x GPU performance for AI vs M4, Nvidia DGX Spark 1 petaflop", "keywords": ["Apple M5", "Nvidia DGX"], "category": "hardware"},
    {"id": "agentic_ai_2025", "news": "Multi-agent systems and Agentic AI integrate RAG for enterprise", "keywords": ["Agentic AI", "RAG"], "category": "software"},
    {"id": "medical_ai_2025", "news": "BInD model designs drugs without molecular data, FDA approved 223 AI devices", "keywords": ["AI drug discovery", "FDA"], "category": "healthcare"},
    {"id": "efficiency_2025", "news": "GPT-3.5 inference cost dropped 280x in 2 years, open-weights closed gap 1.7%", "keywords": ["model efficiency", "open weights"], "category": "optimization"},
]

posts_dir = "_posts"
assets_dir = "assets/images/posts"
os.makedirs(posts_dir, exist_ok=True)
os.makedirs(assets_dir, exist_ok=True)

# ---------- –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ ----------
def normalize_markdown(md: str) -> str:
    """–ü—Ä–∏–≤–æ–¥–∏—Ç –≤—ã–≤–æ–¥ LLM –∫ –≤–∞–ª–∏–¥–Ω–æ–º—É Markdown (Jekyll-safe)"""
    if not md:
        return md
    md = re.sub(r"<[^>]+>", "", md)
    md = re.sub(r"(#+\s.*)", r"\n\1\n", md)
    md = re.sub(r"\n([*-]\s)", r"\n\n\1", md)
    md = re.sub(r"\n(\|.*\|)\n(\|[-: ]+\|)", r"\n\n\1\n\2", md)
    md = re.sub(r"\n{3,}", "\n\n", md)
    return md.strip() + "\n"

# ---------- –ó–∞–≥—Ä—É–∑–∫–∞ —Ç—Ä–µ–Ω–¥–æ–≤ ----------
def load_trends() -> List[Dict]:
    try:
        if os.path.exists(EMBEDDED_TRENDS_FILE):
            with open(EMBEDDED_TRENDS_FILE, "r", encoding="utf-8") as f:
                cache = json.load(f)
                if time.time() - cache.get("last_update", 0) < TRENDS_UPDATE_INTERVAL:
                    logger.info("‚úÖ –¢—Ä–µ–Ω–¥—ã –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏–∑ –∫—ç—à–∞")
                    return cache.get("trends", [])
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∫—ç—à–∞: {e}")
    return update_trends_cache()

def update_trends_cache() -> List[Dict]:
    logger.info("üîÑ –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ç—Ä–µ–Ω–¥–æ–≤...")
    trends: List[Dict] = []
    api_key = os.getenv("NEWSAPI_KEY")
    if api_key:
        try:
            resp = requests.get(
                "https://newsapi.org/v2/everything",
                headers={"X-Api-Key": api_key},
                params={"q": "artificial intelligence", "language": "en", "pageSize": 10},
                timeout=10
            )
            if resp.status_code == 200:
                data = resp.json()
                for i, a in enumerate(data.get("articles", [])[:10]):
                    title = a.get("title", "")
                    trends.append({
                        "id": f"news_{i}_{int(time.time())}",
                        "news": title + ". " + (a.get("description") or ""),
                        "keywords": title.lower().split()[:5],
                        "category": "news"
                    })
        except Exception as e:
            logger.warning(f"‚ùå NewsAPI: {e}")
    if not trends:
        try:
            import feedparser
            feeds = [
                "https://www.artificialintelligence-news.com/feed/",
                "https://venturebeat.com/ai/feed/"
            ]
            ts = int(time.time())
            for url in feeds:
                feed = feedparser.parse(url)
                for i, e in enumerate(feed.entries[:5]):
                    title = e.get("title", "")
                    trends.append({
                        "id": f"rss_{i}_{ts}",
                        "news": title + ". " + e.get("description", "")[:200],
                        "keywords": title.lower().split()[:5],
                        "category": "rss"
                    })
        except Exception as e:
            logger.warning(f"‚ùå RSS: {e}")
    if not trends:
        logger.warning("‚ö†Ô∏è –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–µ —Ç—Ä–µ–Ω–¥—ã")
        trends = EMBEDDED_TRENDS
    try:
        with open(EMBEDDED_TRENDS_FILE, "w", encoding="utf-8") as f:
            json.dump({"last_update": int(time.time()), "trends": trends}, f)
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –∫—ç—à: {e}")
    return trends

# ---------- –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–≥–æ–ª–æ–≤–∫–∞ ----------
def generate_title(client: Groq, trend: Dict, article_type: str) -> str:
    prompt = (
        f"–°–æ–∑–¥–∞–π –û–î–ò–ù —Ü–µ–ø–ª—è—é—â–∏–π –∑–∞–≥–æ–ª–æ–≤–æ–∫ (5‚Äì12 —Å–ª–æ–≤) –¥–ª—è —Å—Ç–∞—Ç—å–∏ —Ç–∏–ø–∞ '{article_type}'.\n"
        f"–¢–µ–º–∞: {trend['news']}.\n"
        "–°—Ç–∏–ª—å: –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ, –ø–æ–ª–µ–∑–Ω–æ, –∏–Ω—Ç—Ä–∏–≥—É—é—â–µ, —Å —Ü–∏—Ñ—Ä–∞–º–∏ –∏–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º.\n"
        "–ó–∞–ø—Ä–µ—â–µ–Ω–æ: –ø–æ–ª–∏—Ç–∏–∫–∞, —Å—Ç—Ä–∞–Ω—ã, —Ä–µ–≥—É–ª—è—Ç–æ—Ä—ã, –∑–∞–∫–æ–Ω—ã, —É–∫–∞–∑—ã, –ª–∏–¥–µ—Ä—ã.\n"
        "–†–∞–∑—Ä–µ—à–µ–Ω–æ: –ò–ò, —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏, –ø—Ä–æ–¥—É–∫—Ç—ã, –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è, —Ä—ã–Ω–æ–∫, –º–µ—Ç—Ä–∏–∫–∏.\n"
        "–¢–æ–ª—å–∫–æ –∑–∞–≥–æ–ª–æ–≤–æ–∫, –±–µ–∑ –∫–∞–≤—ã—á–µ–∫."
    )
    resp = client.chat.completions.create(
        messages=[
            {"role": "system", "content": "–†—É—Å—Å–∫–∏–π —Ç–µ—Ö-—Ä–µ–¥–∞–∫—Ç–æ—Ä. –î–µ–ª–∞–π –∑–∞–≥–æ–ª–æ–≤–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ —Ö–æ—á–µ—Ç—Å—è –æ—Ç–∫—Ä—ã—Ç—å."},
            {"role": "user", "content": prompt},
        ],
        model="llama-3.1-8b-instant",
        max_tokens=30,
        temperature=1.0
    )
    title = resp.choices[0].message.content.strip()
    title = re.sub(r"[^\w\s-]", "", title)[:80]
    logger.info(f"üì∞ –ó–∞–≥–æ–ª–æ–≤–æ–∫: {title}")
    return title

# ---------- –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—Ç–∞—Ç—å–∏ ----------
def generate_article(client: Groq, trend: Dict, article_type: str) -> str:
    system_prompt = f"""–í—ã ‚Äî –æ–ø—ã—Ç–Ω—ã–π —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –∂—É—Ä–Ω–∞–ª–∏—Å—Ç –ø–æ –ò–ò. –ê—É–¥–∏—Ç–æ—Ä–∏—è: —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∏, –∏–Ω–∂–µ–Ω–µ—Ä—ã, —Ñ–∞—É–Ω–¥–µ—Ä—ã, —Ç–µ—Ö-—ç–Ω—Ç—É–∑–∏–∞—Å—Ç—ã.
–°–¢–†–û–ì–û –∑–∞–ø—Ä–µ—â–µ–Ω–æ: –ø–æ–ª–∏—Ç–∏–∫–∞, —Å—Ç—Ä–∞–Ω—ã, —Ä–µ–≥—É–ª—è—Ç–æ—Ä—ã, –∑–∞–∫–æ–Ω—ã, —É–∫–∞–∑—ã, –ª–∏–¥–µ—Ä—ã, –≤–µ–¥–æ–º—Å—Ç–≤–∞.
–§–æ–∫—É—Å: —Ü–∏—Ñ—Ä—ã, —Å—Ä–∞–≤–Ω–µ–Ω–∏—è, —Ä–µ–∞–ª—å–Ω—ã–µ –∫–µ–π—Å—ã, –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∞—è –ø–æ–ª—å–∑–∞
–§–æ—Ä–º–∞—Ç: Markdown, ## –ø–æ–¥–∑–∞–≥–æ–ª–æ–≤–∫–∏, —Å–ø–∏—Å–∫–∏, —Ç–∞–±–ª–∏—Ü—ã, –ø—Ä–∏–º–µ—Ä—ã
–¢–µ–º–∞: {trend['news']}
"""
    user_prompt = (
        f"–ù–∞–ø–∏—à–∏—Ç–µ –ø–æ–ª–Ω—É—é —Å—Ç–∞—Ç—å—é —Ç–∏–ø–∞ '{article_type}' (1500‚Äì3000 —Å–ª–æ–≤).\n"
        "- –º–∏–Ω–∏–º—É–º 2 —Ç–∞–±–ª–∏—Ü—ã\n"
        "- —Ä–µ–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏\n"
        "- –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–º–µ—Ä—ã\n"
        "- –≤—ã–≤–æ–¥—ã –∏ –ø—Ä–æ–≥–Ω–æ–∑—ã\n"
    )

    for attempt in range(3):
        resp = client.chat.completions.create(
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            model="llama-3.3-70b-versatile",
            max_tokens=4000,
            temperature=0.85
        )
        content = normalize_markdown(resp.choices[0].message.content)
        if re.search(r"–ø–æ–ª–∏—Ç–∏–∫", content, re.IGNORECASE):
            logger.warning("‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –ø–æ–ª–∏—Ç–∏–∫–∞ ‚Äî —Ä–µ–≥–µ–Ω–µ—Ä–∞—Ü–∏—è")
            continue
        return content
    raise ValueError("–°—Ç–∞—Ç—å—è –Ω–µ –ø—Ä–æ—à–ª–∞ –ø—Ä–æ–≤–µ—Ä–∫—É –Ω–∞ –ø–æ–ª–∏—Ç–∏–∫—É")

# ---------- –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è ----------
def generate_image(title, trend, post_num):
    path = f"{assets_dir}/post-{post_num}.png"

    # 1Ô∏è‚É£ HuggingFace
    try:
        from PIL import Image
        import io
        # –∑–¥–µ—Å—å –≤—Å—Ç–∞–≤—å—Ç–µ –≤–∞—à –∫–æ–¥ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ HF
        # img_bytes = ...
        raise NotImplementedError
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è HF –æ—à–∏–±–∫–∞: {e}")

    # 2Ô∏è‚É£ ClipDrop
    clipdrop_key = os.getenv("CLIPDROP_API_KEY")
    if clipdrop_key:
        try:
            prompt = f"Ultra-realistic photo of {title}. {trend['news'][:120]}. Cinematic, 8K."
            resp = requests.post(
                "https://clipdrop-api.co/text-to-image/v1",
                files={"prompt": (None, prompt)},
                headers={"x-api-key": clipdrop_key},
                timeout=90
            )
            if resp.status_code == 200:
                with open(path, "wb") as f:
                    f.write(resp.content)
                logger.info("üñº ClipDrop image generated")
                return path
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è ClipDrop –æ—à–∏–±–∫–∞: {e}")

    # 3Ô∏è‚É£ Fallback Matplotlib PNG
    try:
        import matplotlib.pyplot as plt
        years = ["2023","2024","2025"]
        values = [random.randint(40,100) for _ in years]
        plt.figure(figsize=(12,6))
        plt.plot(years, values, marker="o", linewidth=3)
        plt.title("AI Trend Growth")
        plt.tight_layout()
        plt.savefig(path, dpi=150)
        plt.close()
        logger.info("üñº PNG fallback")
        return path
    except Exception as e:
        logger.error(f"‚ùå Fallback –æ—à–∏–±–∫–∞: {e}")
        return None

# ---------- –ü—É–±–ª–∏–∫–∞—Ü–∏—è –≤ Telegram ----------
def send_telegram(title, content, image_path):
    if not os.getenv("TELEGRAM_BOT_TOKEN") or not os.getenv("TELEGRAM_CHAT_ID"):
        logger.warning("‚ö†Ô∏è Telegram –ø—Ä–æ–ø—É—â–µ–Ω (–Ω–µ—Ç –∫–ª—é—á–µ–π)")
        return
    teaser = ' '.join(content.split()[:30]) + '‚Ä¶'

    def esc(text):
        return re.sub(r'([_*\[\]\(\)~`>#+\-=|{}.!])', r'\\\1', text)

    message = f"*–ù–æ–≤–∞—è —Å—Ç–∞—Ç—å—è*\n\n{esc(teaser)}\n\n[–ß–∏—Ç–∞—Ç—å –Ω–∞ —Å–∞–π—Ç–µ]({BASE_URL})\n\n{esc('#–ò–ò #LybraAI')}"
    try:
        resp = requests.post(
            f"https://api.telegram.org/bot{os.getenv('TELEGRAM_BOT_TOKEN')}/sendPhoto",
            data={"chat_id": os.getenv("TELEGRAM_CHAT_ID"),
                  "caption": message,
                  "parse_mode": "MarkdownV2"},
            files={"photo": open(image_path, "rb")}
        )
        logger.info(f"üì¢ Telegram —Å—Ç–∞—Ç—É—Å: {resp.status_code}")
    except Exception as e:
        logger.error(f"‚ùå Telegram –æ—à–∏–±–∫–∞: {e}")

# ---------- MAIN ----------
def main():
    logger.info("üöÄ –ó–∞–ø—É—Å–∫ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏")
    client = Groq(api_key=os.getenv("GROQ_API_KEY"))
    trends = load_trends()
    if not trends:
        logger.error("‚ùå –¢—Ä–µ–Ω–¥—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        return False

    trend = random.choice(trends)
    article_type = random.choice(["–û–±–∑–æ—Ä", "–£—Ä–æ–∫", "–°—Ç–∞—Ç—å—è", "–ú–∞—Å—Ç–µ—Ä-–∫–ª–∞—Å—Å"])

    title = generate_title(client, trend, article_type)
    try:
        content = generate_article(client, trend, article_type)
    except ValueError as e:
        logger.error(f"‚ùå {e}")
        return False

    image_files = glob.glob(f"{assets_dir}/*.png") + glob.glob(f"{assets_dir}/*.jpg")
    post_num = len(image_files) + 1
    image_path = generate_image(title, trend, post_num)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç–∞—Ç—å—é
    today = datetime.date.today()
    slug = re.sub(r"[^\w-]", "-", title.lower())
    slug = re.sub(r"-{2,}", "-", slug).strip("-")[:50]
    filename = f"{posts_dir}/{today}-{slug}.md"
    front_matter = {
        "title": title,
        "date": f"{today} 00:00:00 +0000",
        "layout": "post",
        "image": f"/assets/images/posts/post-{post_num}.png",
        "description": f"{article_type.lower()} –æ {trend['keywords'][0]} 2025",
        "tags": ["–ò–ò", "—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏", article_type.lower()] + trend["keywords"],
    }
    with open(filename, "w", encoding="utf-8") as f:
        f.write("---\n")
        yaml.dump(front_matter, f, allow_unicode=True, sort_keys=False)
        f.write("---\n\n")
        f.write(content)
    logger.info(f"üíæ –°—Ç–∞—Ç—å—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {filename}")

    # –ü—É–±–ª–∏–∫–∞—Ü–∏—è –≤ Telegram
    if image_path:
        send_telegram(title, content, image_path)
    return True

if __name__ == "__main__":
    success = main()
    raise SystemExit(0 if success else 1)
