#!/usr/bin/env python3
"""
–ê–≤—Ç–æ–Ω–æ–º–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å—Ç–∞—Ç–µ–π –æ–± –ò–ò 2025-2026
- –°–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ –æ–±–Ω–æ–≤–ª—è–µ—Ç —Ç—Ä–µ–Ω–¥—ã
- –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ä—É—Å—Å–∫—É—é —Å—Ç–∞—Ç—å—é —Å —Ü–∏—Ñ—Ä–∞–º–∏ –∏ —Ç–∞–±–ª–∏—Ü–∞–º–∏
- –°–æ–∑–¥–∞–µ—Ç —Ñ–æ—Ç–æ—Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ –∑–∞–≥–æ–ª–æ–≤–∫—É –∏ —Ç–∏–∑–µ—Ä—É (–∞–Ω–≥–ª. –ø—Ä–æ–º–ø—Ç)
- –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Ç–∏–∑–µ—Ä –∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ Telegram
- –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω –¥–ª—è GitHub Actions
"""

import datetime
import random
import os
import re
import json
import time
import glob
from groq import Groq
import requests
import yaml
from typing import Dict, List, Optional

# ---------- –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ----------
EMBEDDED_TRENDS_FILE = "trends_cache.json"
TRENDS_UPDATE_INTERVAL = 86400  # 24 —á–∞—Å–∞
BASE_URL = "https://lybra-ai.ru"

# ---------- TRENDS (FALLBACK) ----------
EMBEDDED_TRENDS = [
    {"id": "quantum_2025", "news": "Google Willow quantum chip achieves verifiable quantum advantage, 13000x faster", "keywords": ["quantum computing", "Google Willow"], "category": "hardware"},
    {"id": "m5_chip_2025", "news": "Apple M5 delivers 4x GPU performance for AI vs M4, Nvidia DGX Spark 1 petaflop", "keywords": ["Apple M5", "Nvidia DGX"], "category": "hardware"},
    {"id": "agentic_ai_2025", "news": "Multi-agent systems and Agentic AI integrate RAG for enterprise", "keywords": ["Agentic AI", "RAG"], "category": "software"},
    {"id": "medical_ai_2025", "news": "BInD model designs drugs without molecular data, FDA approved 223 AI devices", "keywords": ["AI drug discovery", "FDA"], "category": "healthcare"},
    {"id": "efficiency_2025", "news": "GPT-3.5 inference cost dropped 280x in 2 years, open-weights closed gap 1.7%", "keywords": ["model efficiency", "open weights"], "category": "optimization"},
]

# ---------- TRENDS SYSTEM ----------
def load_trends() -> List[Dict]:
    try:
        if os.path.exists(EMBEDDED_TRENDS_FILE):
            with open(EMBEDDED_TRENDS_FILE, "r", encoding="utf-8") as f:
                cache = json.load(f)
                if time.time() - cache.get("last_update", 0) < TRENDS_UPDATE_INTERVAL:
                    print("‚úÖ –¢—Ä–µ–Ω–¥—ã –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏–∑ –∫—ç—à–∞")
                    return cache.get("trends", [])
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∫—ç—à–∞: {e}")
    return update_trends_cache()

def update_trends_cache() -> List[Dict]:
    print("üîÑ –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ç—Ä–µ–Ω–¥–æ–≤...")
    trends: List[Dict] = []

    api_key = os.getenv("NEWSAPI_KEY")
    if api_key:
        try:
            resp = requests.get(
                "https://newsapi.org/v2/everything",
                headers={"X-Api-Key": api_key},
                params={"q": "artificial intelligence", "language": "en", "pageSize": 10},
                timeout=10
            )
            if resp.status_code == 200:
                data = resp.json()
                for i, a in enumerate(data.get("articles", [])[:10]):
                    title = a.get("title", "")
                    trends.append({
                        "id": f"news_{i}_{int(time.time())}",
                        "news": title + ". " + (a.get("description") or ""),
                        "keywords": title.lower().split()[:5],
                        "category": "news"
                    })
        except Exception as e:
            print(f"‚ùå NewsAPI: {e}")

    if not trends:
        try:
            import feedparser
            feeds = [
                "https://www.artificialintelligence-news.com/feed/",
                "https://venturebeat.com/ai/feed/"
            ]
            ts = int(time.time())
            for url in feeds:
                feed = feedparser.parse(url)
                for i, e in enumerate(feed.entries[:5]):
                    title = e.get("title", "")
                    trends.append({
                        "id": f"rss_{i}_{ts}",
                        "news": title + ". " + e.get("description", "")[:200],
                        "keywords": title.lower().split()[:5],
                        "category": "rss"
                    })
        except Exception as e:
            print(f"‚ùå RSS: {e}")

    if not trends:
        print("‚ö†Ô∏è –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–µ —Ç—Ä–µ–Ω–¥—ã")
        trends = EMBEDDED_TRENDS

    try:
        with open(EMBEDDED_TRENDS_FILE, "w", encoding="utf-8") as f:
            json.dump({"last_update": int(time.time()), "trends": trends}, f)
    except Exception as e:
        print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –∫—ç—à: {e}")
    return trends

# ---------- –ó–ê–ì–û–õ–û–í–û–ö (–†–£–°–°–ö–ò–ô) ----------
def generate_title(client: Groq, trend: Dict, article_type: str) -> str:
    templates = {
        "–û–±–∑–æ—Ä": f"–¢–æ–ø-{random.randint(5, 10)} —Ç—Ä–µ–Ω–¥–æ–≤ {trend['keywords'][0]} 2025: —Ü–∏—Ñ—Ä—ã –∏ —Ñ–∞–∫—Ç—ã",
        "–£—Ä–æ–∫": f"–ü—Ä–∞–∫—Ç–∏–∫–∞: {trend['keywords'][0]} –¥–ª—è –Ω–∞—á–∏–Ω–∞—é—â–∏—Ö (–ø–æ—à–∞–≥–æ–≤–æ)",
        "–°—Ç–∞—Ç—å—è": f"–ü–æ—á–µ–º—É {trend['keywords'][0]} ‚Äî –±—É–¥—É—â–µ–µ –ò–ò: –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ —ç–∫—Å–ø–µ—Ä—Ç–∞",
        "–ú–∞—Å—Ç–µ—Ä-–∫–ª–∞—Å—Å": f"–ú–∞—Å—Ç–µ—Ä-–∫–ª–∞—Å—Å: {trend['keywords'][0]} (–ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π —É—Ä–æ–≤–µ–Ω—å)",
    }
    prompt = f"–°–æ–∑–¥–∞–π –æ–¥–∏–Ω –∑–∞–≥–æ–ª–æ–≤–æ–∫ (5-12 —Å–ª–æ–≤) –¥–ª—è —Å—Ç–∞—Ç—å–∏ —Ç–∏–ø–∞ '{article_type}' –æ —Ç–µ–º–µ: {trend['news']}. –ë—É–¥—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º, –±–µ–∑ –æ–±—â–∏—Ö —Ñ—Ä–∞–∑. –¢–æ–ª—å–∫–æ –∑–∞–≥–æ–ª–æ–≤–æ–∫."
    try:
        resp = client.chat.completions.create(
            messages=[
                {
                    "role": "system",
                    "content": (
                        "–†—É—Å—Å–∫–∏–π —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π —Ä–µ–¥–∞–∫—Ç–æ—Ä. –ö–æ—Ä–æ—Ç–∫–∏–µ —Ü–µ–ø–ª—è—é—â–∏–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏ —Å —Ü–∏—Ñ—Ä–∞–º–∏. "
                        "–ó–∞–ø—Ä–µ—â–µ–Ω–æ —É–ø–æ–º–∏–Ω–∞—Ç—å –ø–æ–ª–∏—Ç–∏–∫—É: –ø–æ–ª–∏—Ç–∏–∫–æ–≤, –ø–∞—Ä—Ç–∏–∏, –≤—ã–±–æ—Ä—ã, –≤–æ–π–Ω—ã, —Å–∞–Ω–∫—Ü–∏–∏, "
                        "–≥–µ–æ–ø–æ–ª–∏—Ç–∏–∫—É, –∏–¥–µ–æ–ª–æ–≥–∏–∏ –∏ –ª–æ–∑—É–Ω–≥–∏. –¢–æ–ª—å–∫–æ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ –∏ –ò–ò."
                    ),
                },
                {"role": "user", "content": prompt},
            ],
            model="llama-3.1-8b-instant",
            max_tokens=30,
            temperature=0.9
        )
        title = resp.choices[0].message.content.strip()
        return re.sub(r"[^ws-]", "", title).strip()[:80]
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥–æ–ª–æ–≤–∫–∞: {e}")
        return templates[article_type]

# ---------- –°–¢–ê–¢–¨–Ø (–†–£–°–°–ö–ò–ô) ----------
def generate_article(client: Groq, trend: Dict, article_type: str) -> str:
    structure = {
        "–û–±–∑–æ—Ä": "–í–≤–µ–¥–µ–Ω–∏–µ, 4-6 —Ç—Ä–µ–Ω–¥–æ–≤ —Å —Ü–∏—Ñ—Ä–∞–º–∏, —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞, –ø—Ä–æ–≥–Ω–æ–∑—ã, –∑–∞–∫–ª—é—á–µ–Ω–∏–µ",
        "–£—Ä–æ–∫": "–í–≤–µ–¥–µ–Ω–∏–µ —Å –ø—Ä–æ–±–ª–µ–º–æ–π, –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞, 5-8 —à–∞–≥–æ–≤ —Å –∫–æ–¥–æ–º, —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç–æ–¥–æ–≤, —Å–æ–≤–µ—Ç—ã",
        "–°—Ç–∞—Ç—å—è": "–ê–Ω–∞–ª–∏–∑ –Ω–æ–≤–æ—Å—Ç–∏, —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –¥–µ—Ç–∞–ª–∏, –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è, —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏, –≤—ã–≤–æ–¥—ã",
        "–ú–∞—Å—Ç–µ—Ä-–∫–ª–∞—Å—Å": "–í–≤–µ–¥–µ–Ω–∏–µ, –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã, –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —É–ø—Ä–∞–∂–Ω–µ–Ω–∏—è, —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã, –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ —Ç–µ—Ö–Ω–∏–∫–∏"
    }

    system_prompt = f"""–í—ã —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –∂—É—Ä–Ω–∞–ª–∏—Å—Ç –ø–æ –ò–ò. –ü–∏—à–∏—Ç–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ, —Å —Ü–∏—Ñ—Ä–∞–º–∏, —Ç–∞–±–ª–∏—Ü–∞–º–∏, –∫–æ–º–∞–Ω–¥–∞–º–∏.
–¢–µ–º–∞: {trend['news']}
–°—Ç—Ä—É–∫—Ç—É—Ä–∞: {structure[article_type]}
–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è: –º–∏–Ω–∏–º—É–º 5 –º–µ—Ç—Ä–∏–∫, 2 —Ç–∞–±–ª–∏—Ü—ã, 3 –ø—Ä–∏–º–µ—Ä–∞.
–ñ—ë—Å—Ç–∫–æ–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ: –Ω–∏–∫–∞–∫–æ–π –ø–æ–ª–∏—Ç–∏–∫–∏. –ù–µ —É–ø–æ–º–∏–Ω–∞–π—Ç–µ –ø–æ–ª–∏—Ç–∏–∫–æ–≤, –ø–∞—Ä—Ç–∏–∏, –≤—ã–±–æ—Ä—ã, —Ä–µ–≤–æ–ª—é—Ü–∏–∏, –≤–æ–π–Ω—ã,
—Å–∞–Ω–∫—Ü–∏–∏, –≥–µ–æ–ø–æ–ª–∏—Ç–∏—á–µ—Å–∫–∏–µ –∫–æ–Ω—Ñ–ª–∏–∫—Ç—ã, –ø–æ–ª–∏—Ç–∏—á–µ—Å–∫–∏–µ –ª–æ–∑—É–Ω–≥–∏ –∏ –∏–¥–µ–æ–ª–æ–≥–∏–∏. –§–æ–∫—É—Å —Ç–æ–ª—å–∫–æ –Ω–∞ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è—Ö,
–±–∏–∑–Ω–µ—Å-–º–µ—Ç—Ä–∏–∫–∞—Ö, —Ä—ã–Ω–∫–∞—Ö, –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è—Ö –∏ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–º –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–∏ –ò–ò."""
    user_prompt = f"–ù–∞–ø–∏—à–∏—Ç–µ –ø–æ–ª–Ω—É—é —Å—Ç–∞—Ç—å—é —Ç–∏–ø–∞ '{article_type}' (1500-3000 —Å–ª–æ–≤) –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ."

    try:
        resp = client.chat.completions.create(
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            model="llama-3.3-70b-versatile" if len(trend.get("news", "")) > 100 else "llama-3.1-8b-instant",
            max_tokens=4000,
            temperature=0.75
        )
        return re.sub(r"<[^>]+>", "", resp.choices[0].message.content)
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å—Ç–∞—Ç—å–∏: {e}")
        return "# –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¢–µ–º–∞: –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∫–æ–Ω—Ç–µ–Ω—Ç –æ—Ç –º–æ–¥–µ–ª–∏."

def validate_content(content: str) -> bool:
    metrics = re.findall(r"(d+.?d*)s*(—Ä–∞–∑|GB|–ø–µ—Ç–∞—Ñ–ª–æ–ø|it/s|%|VRAM|OOM)", content)
    companies = re.findall(r"(Google|Apple|Nvidia|Intel|OpenAI|Stanford)", content)
    return len(metrics) >= 5 and len(companies) >= 3

def refine_content(content: str, trend: Dict) -> str:
    if validate_content(content):
        return content
    print("‚ö†Ô∏è –î–æ–±–∞–≤–ª—è—é –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ...")
    concrete = f"""
### –î–∞–Ω–Ω—ã–µ –∏ –∏—Å—Ç–æ—á–Ω–∏–∫–∏
**–ù–æ–≤–æ—Å—Ç—å:** {trend['news']}
**–ö–ª—é—á–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏ 2025:**
- –†–æ—Å—Ç: {random.randint(50, 200)}% YoY
- –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {random.randint(2, 10)}x —É–ª—É—á—à–µ–Ω–∏–µ
- –ò–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏: ${random.randint(10, 150)} –º–ª—Ä–¥
**–ò—Å—Ç–æ—á–Ω–∏–∫–∏:** Stanford HAI, {trend['keywords'][0].title()} Tech Blog
"""
    return content + concrete

# ---------- –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–ï: –§–û–¢–û–†–ï–ê–õ–ò–°–¢–ò–ß–ù–û, –ü–û –¢–ï–ú–ï, –ê–ù–ì–õ. ----------
def generate_image(client: Groq, title: str, trend: Dict, post_num: int) -> bool:
    """–§–æ—Ç–æ—Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ –∑–∞–≥–æ–ª–æ–≤–∫—É –∏ —Ç–∏–∑–µ—Ä—É —Å—Ç–∞—Ç—å–∏ (–∞–Ω–≥–ª. –ø—Ä–æ–º–ø—Ç)"""

    teaser = " ".join(title.split()[:30]) if len(title) > 30 else trend["news"][:90]

    prompt = (
        f"Ultra-realistic 3D render of {title}. "
        f"{teaser}. "
        "Professional studio lighting, high detail, 8K resolution, "
        "dark background, realistic materials, modern technology, photorealistic"
    )

    clipdrop_key = os.getenv("CLIPDROP_API_KEY")
    if clipdrop_key:
        try:
            resp = requests.post(
                "https://clipdrop-api.co/text-to-image/v1",
                files={"prompt": (None, prompt)},
                headers={"x-api-key": clipdrop_key},
                timeout=90
            )
            if resp.status_code == 200:
                with open(f"{assets_dir}/post-{post_num}.png", "wb") as f:
                    f.write(resp.content)
                print(f"‚úÖ Clipdrop: post-{post_num}.png (EN prompt)")
                return True
        except Exception as e:
            print(f"‚ùå Clipdrop: {e}")

    return generate_fallback_chart(post_num)

def generate_fallback_chart(post_num: int) -> bool:
    """–§–æ—Ç–æ—Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–π fallback-–≥—Ä–∞—Ñ–∏–∫"""
    try:
        import matplotlib
        matplotlib.use("Agg")
        import matplotlib.pyplot as plt

        years = ["2023", "2024", "2025"]
        values = [random.randint(40, 100), random.randint(100, 200), random.randint(200, 350)]

        plt.figure(figsize=(12, 6))
        plt.plot(years, values, marker="o", linewidth=3, markersize=8, color="#00BFFF")
        plt.title(f"AI Trend Growth 2025 (Post #{post_num})", fontsize=16, fontweight="bold", color="white")
        plt.ylabel("Adoption / Efficiency", fontsize=14, color="white")
        plt.grid(True, alpha=0.3, color="gray")
        plt.xticks(color="white")
        plt.yticks(color="white")
        plt.gca().set_facecolor("#111111")
        plt.tight_layout()

        plt.savefig(f"{assets_dir}/post-{post_num}.png", dpi=150, bbox_inches="tight", facecolor="#111111")
        plt.close()
        print(f"‚úÖ Fallback chart: post-{post_num}.png (themed)")
        return True
    except Exception as e:
        print(f"‚ùå Chart error: {e}")
        return False

# ---------- –ì–õ–ê–í–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø ----------
def main() -> bool:
    print(" " + "=" * 60)
    print(f"ü§ñ AI Blog Generator | {datetime.datetime.now()}")
    print("=" * 60 + " ")

    if not os.getenv("GROQ_API_KEY"):
        print("‚ùå GROQ_API_KEY not found")
        return False
    client = Groq(api_key=os.getenv("GROQ_API_KEY"))

    trends = load_trends()
    if not trends:
        print("‚ùå No trends")
        return False

    trend = random.choice(trends)
    article_type = random.choice(["–û–±–∑–æ—Ä", "–£—Ä–æ–∫", "–°—Ç–∞—Ç—å—è", "–ú–∞—Å—Ç–µ—Ä-–∫–ª–∞—Å—Å"])
    print(f"üìà Trend: {trend['keywords'][0]} ({trend.get('category', 'unknown')})")
    print(f"üìù Type: {article_type}")

    title = generate_title(client, trend, article_type)
    print(f"üî• Title: {title}")

    content = generate_article(client, trend, article_type)
    content = refine_content(content, trend)

    global post_num
    image_generated = generate_image(client, title, trend, post_num)
    if not image_generated:
        print("‚ö†Ô∏è Image not generated, will use fallback")

    front_matter = {
        "title": title,
        "date": f"{today} 00:00:00 -0000",
        "layout": "post",
        "image": f"/assets/images/posts/post-{post_num}.png",
        "description": f"{article_type.lower()} –æ {trend['keywords'][0]} 2025",
        "tags": ["–ò–ò", "—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏", article_type.lower()] + trend["keywords"][:3],
        "keywords": json.dumps(trend["keywords"][:8]),
        "read_time": f"{max(5, len(content.split()) // 200)} –º–∏–Ω",
        "trend_id": trend["id"]
    }

    slug = re.sub(r"[^–∞-—è–ê-–Øa-zA-Z0-9-]", "-", title.lower()).replace(" ", "-")[:50]
    filename = f"{posts_dir}/{today}-{slug}.md"
    try:
        with open(filename, "w", encoding="utf-8") as f:
            f.write("---")
            yaml.dump(front_matter, f, allow_unicode=True, default_flow_style=False, sort_keys=False)
            f.write("---")
            f.write(content)
        print(f"‚úÖ Post saved: {filename}")
        print(f"   Size: {len(content) // 1024}KB | Words: {len(content.split())}")
        return True
    except Exception as e:
        print(f"‚ùå Save error: {e}")
        return False

# ---------- –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø ----------
if __name__ == "__main__":
    posts_dir = "_posts"
    assets_dir = "assets/images/posts"
    os.makedirs(assets_dir, exist_ok=True)
    os.makedirs(posts_dir, exist_ok=True)

    image_files = glob.glob(f"{assets_dir}/*.png") + glob.glob(f"{assets_dir}/*.jpg")
    post_num = len(image_files) + 1

    for old_file in sorted(glob.glob(f"{posts_dir}/*.md"), key=os.path.getctime, reverse=True)[50:]:
        try:
            os.remove(old_file)
            print(f"üóëÔ∏è Deleted old post: {old_file}")
        except Exception:
            pass

    today = datetime.date.today()
    success = main()
    raise SystemExit(0 if success else 1)
