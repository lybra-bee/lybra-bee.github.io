---
title: "Эволюция нейронных сетей: от персептронов до трансформеров"
date: 2025-09-27 00:00:00 -0000
image: /assets/images/posts/post-4.png
---
# Эволюция нейронных сетей: от персептронов до трансформеров

## Мастер-класс

Нейронные сети — сердце ИИ. В 1957 году Фрэнк Розенблатт создал персептрон: однослойную модель для бинарной классификации. Проблема — неспособность решать нелинейные задачи (XOR), что вызвало "зиму ИИ" после критики Мински (1969).

Возрождение в 1980-х: backpropagation (Румельхарт) позволил многослойным персептронам (MLP) обучаться сложным паттернам. 2000-е: CNN (ЛеКун) для изображений, RNN для последовательностей, но с исчезающими градиентами — спасли LSTM (1997).

Трансформеры (2017, Vaswani) — прорыв: self-attention для параллельного обучения. BERT и GPT изменили NLP. Сегодня Vision Transformers работают с изображениями. Будущее: энергоэффективные модели для устройств.

Практика: В PyTorch создайте трансформер:
```python
import torch.nn as nn
class SimpleTransformer(nn.Module):
    def __init__(self):
        super().__init__()
        self.attention = nn.MultiheadAttention(embed_dim=512, num_heads=8)
    # Далее логика forward...
