#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
generate_content.py
–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∏ —Å—Ç–∞—Ç—å—é (OpenRouter -> Groq fallback),
–æ–±–Ω–æ–≤–ª—è–µ—Ç data/gallery.yaml –∏ data/gallery.json,
—É–¥–∞–ª—è–µ—Ç —Å—Ç–∞—Ä—ã–µ .md —Å—Ç–∞—Ç—å–∏ (–æ—Å—Ç–∞–≤–ª—è–µ—Ç KEEP_POSTS), –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–µ —Ç—Ä–æ–≥–∞–µ—Ç.
"""

import os
import sys
import time
import json
import yaml
import logging
import requests
import glob
from datetime import datetime
from slugify import slugify

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")

# –ü–∞–ø–∫–∏ / –∫–æ–Ω—Å—Ç–∞–Ω—Ç—ã
POSTS_DIR = "content/posts"
STATIC_IMAGES_DIR = "static/images/posts"
DATA_DIR = "data"
GALLERY_YAML = os.path.join(DATA_DIR, "gallery.yaml")
GALLERY_JSON = os.path.join(DATA_DIR, "gallery.json")
KEEP_POSTS = 10  # —Å–∫–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Å—Ç–∞—Ç–µ–π —Å–æ—Ö—Ä–∞–Ω—è—Ç—å

# API –∫–ª—é—á–∏ (–ø–µ—Ä–µ–¥–∞—é—Ç—Å—è –≤ workflow / secrets)
OPENROUTER_API_KEY = os.environ.get("OPENROUTER_API_KEY")
GROQ_API_KEY = os.environ.get("GROQ_API_KEY")

# Ensure dirs exist
os.makedirs(POSTS_DIR, exist_ok=True)
os.makedirs(STATIC_IMAGES_DIR, exist_ok=True)
os.makedirs(DATA_DIR, exist_ok=True)

# --- Helpers ---
def safe_yaml_value(v):
    if v is None:
        return ""
    return str(v).replace("\r", " ").replace("\n", " ").strip()

def try_extract_openrouter_response(data):
    try:
        if isinstance(data, dict):
            if "choices" in data and data["choices"]:
                c = data["choices"][0]
                if isinstance(c, dict):
                    if "message" in c and isinstance(c["message"], dict) and "content" in c["message"]:
                        return c["message"]["content"]
                    if "text" in c:
                        return c["text"]
            if "output" in data and isinstance(data["output"], list) and data["output"]:
                first = data["output"][0]
                if isinstance(first, dict) and "content" in first:
                    return first["content"]
        return None
    except Exception:
        return None

def generate_with_openrouter_chat(prompt, max_tokens=800, model="gpt-4o-mini"):
    if not OPENROUTER_API_KEY:
        return None
    url = "https://openrouter.ai/api/v1/chat/completions"
    headers = {"Authorization": f"Bearer {OPENROUTER_API_KEY}", "Content-Type": "application/json"}
    payload = {"model": model, "messages": [{"role": "user", "content": prompt}], "max_tokens": max_tokens}
    try:
        r = requests.post(url, headers=headers, json=payload, timeout=60)
        r.raise_for_status()
        r.encoding = "utf-8"
        data = r.json()
        return try_extract_openrouter_response(data)
    except Exception as e:
        logging.warning(f"‚ö†Ô∏è OpenRouter(chat) failed: {e}")
    return None

def generate_with_openrouter_completions(prompt, max_tokens=1200, model="gpt-4o-mini"):
    if not OPENROUTER_API_KEY:
        return None
    url = "https://openrouter.ai/api/v1/completions"
    headers = {"Authorization": f"Bearer {OPENROUTER_API_KEY}", "Content-Type": "application/json"}
    payload = {"model": model, "input": prompt, "max_tokens": max_tokens}
    try:
        r = requests.post(url, headers=headers, json=payload, timeout=60)
        r.raise_for_status()
        r.encoding = "utf-8"
        data = r.json()
        if isinstance(data, dict):
            if "output" in data and isinstance(data["output"], list) and data["output"]:
                return data["output"][0].get("content")
            if "choices" in data and data["choices"]:
                return data["choices"][0].get("text")
    except Exception as e:
        logging.warning(f"‚ö†Ô∏è OpenRouter(completions) failed: {e}")
    return None

def generate_with_groq_chat(prompt, max_tokens=1200, model="gpt-4o-mini"):
    if not GROQ_API_KEY:
        return None
    endpoints = [
        "https://api.groq.com/openai/v1/chat/completions",
        "https://api.groq.com/v1/chat/completions",
        "https://api.groq.com/v1/predict",
    ]
    headers = {"Authorization": f"Bearer {GROQ_API_KEY}", "Content-Type": "application/json"}
    for url in endpoints:
        try:
            payload = {"model": model, "messages": [{"role": "user", "content": prompt}], "max_tokens": max_tokens}
            r = requests.post(url, headers=headers, json=payload, timeout=60)
            r.raise_for_status()
            r.encoding = "utf-8"
            data = r.json()
            if "choices" in data and data["choices"]:
                c = data["choices"][0]
                if "message" in c and "content" in c["message"]:
                    return c["message"]["content"].strip()
                if "text" in c:
                    return c["text"].strip()
            if "prediction" in data:
                return str(data["prediction"]).strip()
        except Exception as e:
            logging.warning(f"‚ö†Ô∏è Groq endpoint {url} failed: {e}")
    return None

# --- High level generators ---
def generate_title(year):
    prompt = f"""
–°–æ—Å—Ç–∞–≤—å –∫–æ—Ä–æ—Ç–∫–∏–π (5‚Äì9 —Å–ª–æ–≤) –∑–∞–≥–æ–ª–æ–≤–æ–∫ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ –¥–ª—è —Å—Ç–∞—Ç—å–∏ –æ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–∏ –ò–ò –∏ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π –≤ {year} –≥–æ–¥—É.
–û–Ω –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º (–ø—Ä–∏–º–µ—Ä: ¬´–ò–ò –≤ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–µ –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏–π¬ª, ¬´–ù–µ–π—Ä–æ—Å–µ—Ç–∏ –≤ —Å—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤–µ¬ª).
–ò–∑–±–µ–≥–∞–π —Å–ª–æ–≤ ¬´–Ω–æ–≤–æ—Å—Ç–∏¬ª, ¬´—Ç—Ä–µ–Ω–¥—ã¬ª –∏ –æ–±—â–∏—Ö —Ñ—Ä–∞–∑. –°–¥–µ–ª–∞–π —Ç–∞–∫, —á—Ç–æ–±—ã –∑–∞–≥–æ–ª–æ–≤–æ–∫ –≤—ã–≥–ª—è–¥–µ–ª –∫–∞–∫ —Å—Ç–∞—Ç—å—è –≤ –±–ª–æ–≥–µ, –∞ –Ω–µ —Ä–µ–∫–ª–∞–º–Ω—ã–π —Å–ª–æ–≥–∞–Ω.
"""
    logging.info("üìù –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–≥–æ–ª–æ–≤–∫–∞ (OpenRouter -> Groq)...")
    text = generate_with_openrouter_chat(prompt, max_tokens=70)
    if text:
        return text.strip().strip('"')
    text = generate_with_openrouter_completions(prompt, max_tokens=70)
    if text:
        return text.strip().strip('"')
    text = generate_with_groq_chat(prompt, max_tokens=70)
    if text:
        return text.strip().strip('"')
    logging.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∑–∞–≥–æ–ª–æ–≤–æ–∫ –æ—Ç API ‚Äî fallback")
    return f"–ò–ò –∏ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ {year}"

def generate_article_text(title, year):
    prompt = f"""
–ù–∞–ø–∏—à–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—É—é —Å—Ç–∞—Ç—å—é –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ –ø–æ –∑–∞–≥–æ–ª–æ–≤–∫—É: ¬´{title}¬ª. 
–û–±—ä—ë–º: 400‚Äì600 —Å–ª–æ–≤.  
–°—Ç—Ä—É–∫—Ç—É—Ä–∞: –í–≤–µ–¥–µ–Ω–∏–µ ‚Üí 2‚Äì3 —Ä–∞–∑–¥–µ–ª–∞ —Å –ø–æ–¥–∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏ ‚Üí –ó–∞–∫–ª—é—á–µ–Ω–∏–µ.  
–°–¥–µ–ª–∞–π —Å–≤—è–∑–Ω—ã–π —Ç–µ–∫—Å—Ç, –±–µ–∑ –ø—É–Ω–∫—Ç–æ–≤-—Å–ø–∏—Å–∫–æ–≤, —á—Ç–æ–±—ã —ç—Ç–æ –≤—ã–≥–ª—è–¥–µ–ª–æ –∫–∞–∫ –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω—ã–π –ø–æ—Å—Ç –≤ –±–ª–æ–≥–µ.
"""
    logging.info("üìù –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ —Å—Ç–∞—Ç—å–∏ (OpenRouter -> Groq)...")
    text = generate_with_openrouter_chat(prompt, max_tokens=1100)
    if text:
        return text
    text = generate_with_openrouter_completions(prompt, max_tokens=1100)
    if text:
        return text
    text = generate_with_groq_chat(prompt, max_tokens=1100)
    if text:
        return text
    logging.warning("‚ö†Ô∏è –í—Å–µ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä—ã –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–∏ ‚Äî fallback")
    return (
        f"## –í–≤–µ–¥–µ–Ω–∏–µ\n\n–ò—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç –≤ {year} –≥–æ–¥—É –∞–∫—Ç–∏–≤–Ω–æ –≤–Ω–µ–¥—Ä—è–µ—Ç—Å—è –≤ —Ä–∞–∑–Ω—ã–µ —Å—Ñ–µ—Ä—ã.\n\n"
        "## –û—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è\n\n–ò–ò –ø–æ–º–æ–≥–∞–µ—Ç –≤ –º–µ–¥–∏—Ü–∏–Ω–µ, –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–∏, –ø—Ä–æ–º—ã—à–ª–µ–Ω–Ω–æ—Å—Ç–∏ –∏ —Ç–≤–æ—Ä—á–µ—Å—Ç–≤–µ. "
        "–ú—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏ –æ–±—ä–µ–¥–∏–Ω—è—é—Ç —Ç–µ–∫—Å—Ç, –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏ –∑–≤—É–∫.\n\n"
        "## –ó–∞–∫–ª—é—á–µ–Ω–∏–µ\n\n–†–∞–∑–≤–∏—Ç–∏–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç –º–µ–Ω—è—Ç—å –ø–æ–≤—Å–µ–¥–Ω–µ–≤–Ω—É—é –∂–∏–∑–Ω—å."
    )

# --- Save article ---
def save_article(title, text, model_name, slug):
    fm = {
        "title": safe_yaml_value(title),
        "date": datetime.now().astimezone().isoformat(),
        "draft": False,
        "image": "",
        "model": safe_yaml_value(model_name),
        "tags": ["AI", "Tech"],
        "categories": ["–¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏"],
        "author": "AI Generator",
        "description": safe_yaml_value(text[:200] + ("..." if len(text) > 200 else "")),
    }
    filename = os.path.join(POSTS_DIR, f"{slug}.md")
    # –µ—Å–ª–∏ —Ñ–∞–π–ª —É–∂–µ –µ—Å—Ç—å ‚Äî –¥–æ–±–∞–≤–∏–º timestamp –∫ slug
    if os.path.exists(filename):
        slug = f"{slug}-{int(time.time())}"
        filename = os.path.join(POSTS_DIR, f"{slug}.md")
    yaml_block = yaml.safe_dump(fm, allow_unicode=True, default_flow_style=False, sort_keys=False)
    content = f"---\n{yaml_block}---\n\n{text}\n"
    with open(filename, "w", encoding="utf-8") as f:
        f.write(content)
    logging.info(f"‚úÖ Article saved: {filename}")
    return filename

# --- Gallery ---
def rebuild_gallery_from_static(limit=200):
    logging.info("üóÇÔ∏è Rebuilding gallery ...")
    patterns = ["*.png", "*.jpg", "*.jpeg", "*.svg", "*.webp", "*.gif"]
    files = []
    for p in patterns:
        files.extend(glob.glob(os.path.join(STATIC_IMAGES_DIR, p)))
    files = sorted(files, key=os.path.getmtime, reverse=True)
    images = []
    for fpath in files[:limit]:
        fname = os.path.basename(fpath)
        title = os.path.splitext(fname)[0].replace("-", " ").replace("_", " ").title()
        item = {
            "src": f"/images/posts/{fname}",
            "alt": title,
            "title": title,
            "date": datetime.fromtimestamp(os.path.getmtime(fpath)).strftime("%Y-%m-%d")
        }
        images.append(item)
    with open(GALLERY_YAML, "w", encoding="utf-8") as yf:
        yaml.safe_dump(images, yf, allow_unicode=True, default_flow_style=False)
    with open(GALLERY_JSON, "w", encoding="utf-8") as jf:
        json.dump(images, jf, ensure_ascii=False, indent=2)
    logging.info(f"‚úÖ Gallery rebuilt: {len(images)} items")

# --- Cleanup old posts ---
def cleanup_old_posts(keep=KEEP_POSTS):
    md_files = sorted(glob.glob(os.path.join(POSTS_DIR, "*.md")), key=os.path.getmtime, reverse=True)
    for old in md_files[keep:]:
        try:
            os.remove(old)
            logging.info(f"üóëÔ∏è Removed old article: {old}")
        except Exception as e:
            logging.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å {old}: {e}")

# --- Main ---
def main():
    year = datetime.now().year
    cleanup_old_posts()
    rebuild_gallery_from_static()
    title = generate_title(year)
    slug = slugify(title)
    article_text = generate_article_text(title, year)
    save_article(title, article_text, model_name="openrouter:gpt-4o-mini", slug=slug)
    logging.info("üéâ Content generation complete.")

if __name__ == "__main__":
    main()
