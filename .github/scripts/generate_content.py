#!/usr/bin/env python3
import os
import json
import random
from datetime import datetime, timezone
import shutil
import re
import textwrap
from PIL import Image, ImageDraw, ImageFont
import logging
import base64
import requests
import openai

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)

# –ö–ª—é—á–∏ (–Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º–∏)
OPENAI_KEY = os.getenv("OPENAI_API_KEY")
UNSPLASH_KEY = os.getenv("UNSPLASH_ACCESS_KEY")
PIXABAY_KEY = os.getenv("PIXABAY_API_KEY")
DEEPAI_KEY = os.getenv("DEEPAI_API_KEY")

if OPENAI_KEY:
    openai.api_key = OPENAI_KEY

# ======== –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–º—ã ========
def generate_ai_trend_topic():
    current_trends_2025 = [
        "Multimodal AI –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏ –∞—É–¥–∏–æ –≤ –µ–¥–∏–Ω—ã—Ö –º–æ–¥–µ–ª—è—Ö",
        "AI –∞–≥–µ–Ω—Ç—ã –∞–≤—Ç–æ–Ω–æ–º–Ω—ã–µ —Å–∏—Å—Ç–µ–º—ã —Å–ø–æ—Å–æ–±–Ω—ã–µ –≤—ã–ø–æ–ª–Ω—è—Ç—å —Å–ª–æ–∂–Ω—ã–µ –∑–∞–¥–∞—á–∏",
        "–ö–≤–∞–Ω—Ç–æ–≤—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –∏ –º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –ø—Ä–æ—Ä—ã–≤ –≤ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏",
        "–ù–µ–π—Ä–æ–º–æ—Ä—Ñ–Ω—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è —ç–Ω–µ—Ä–≥–æ—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π",
        "Generative AI —Å–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –∫–æ–¥–∞ –∏ –¥–∏–∑–∞–π–Ω–æ–≤ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–º –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–æ–º",
        "Edge AI –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ –±–µ–∑ –æ–±–ª–∞—á–Ω–æ–π –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏",
        "AI –¥–ª—è –∫–∏–±–µ—Ä–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –ø—Ä–µ–¥–∏–∫—Ç–∏–≤–Ω–∞—è –∑–∞—â–∏—Ç–∞ –æ—Ç —É–≥—Ä–æ–∑",
        "–≠—Ç–∏—á–Ω—ã–π AI –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ–µ —Ä–∞–∑–≤–∏—Ç–∏–µ –∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞",
        "AI –≤ healthcare –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞ –ª–µ–∫–∞—Ä—Å—Ç–≤ –∏ –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–µ–¥–∏—Ü–∏–Ω–∞",
        "–ê–≤—Ç–æ–Ω–æ–º–Ω—ã–µ —Å–∏—Å—Ç–µ–º—ã –±–µ—Å–ø–∏–ª–æ—Ç–Ω—ã–π —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç –∏ —Ä–æ–±–æ—Ç–æ—Ç–µ—Ö–Ω–∏–∫–∞",
        "AI –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Å–∂–∞—Ç–∏–µ –º–æ–¥–µ–ª–µ–π –∏ —É—Å–∫–æ—Ä–µ–Ω–∏–µ inference",
        "–î–æ–≤–µ—Ä–µ–Ω–Ω—ã–π AI –æ–±—ä—è—Å–Ω–∏–º—ã–µ –∏ –ø—Ä–æ–∑—Ä–∞—á–Ω—ã–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã",
        "AI –¥–ª—è –∫–ª–∏–º–∞—Ç–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —ç–Ω–µ—Ä–≥–æ–ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏—è –∏ —ç–∫–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ —Ä–µ—à–µ–Ω–∏—è",
        "–ü–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–µ AI –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç—ã –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ü–∏—Ñ—Ä–æ–≤—ã–µ –ø–æ–º–æ—â–Ω–∏–∫–∏",
        "AI –≤ –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–∏ –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –∏ –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —É—á–µ–±–Ω—ã–µ –ø–ª–∞–Ω—ã"
    ]
    application_domains = [
        "–≤ –≤–µ–± —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ –∏ cloud native –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è—Ö",
        "–≤ –º–æ–±–∏–ª—å–Ω—ã—Ö –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è—Ö –∏ IoT —ç–∫–æ—Å–∏—Å—Ç–µ–º–∞—Ö",
        "–≤ –æ–±–ª–∞—á–Ω—ã—Ö —Å–µ—Ä–≤–∏—Å–∞—Ö –∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã—Ö —Å–∏—Å—Ç–µ–º–∞—Ö",
        "–≤ –∞–Ω–∞–ª–∏–∑–µ –±–æ–ª—å—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö –∏ –±–∏–∑–Ω–µ—Å –∞–Ω–∞–ª–∏—Ç–∏–∫–µ",
        "–≤ –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–π –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –∏ –∫–∏–±–µ—Ä–∑–∞—â–∏—Ç–µ",
        "–≤ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–π –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–µ –∏ –±–∏–æ—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è—Ö",
        "–≤ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è—Ö –∏ —Ñ–∏–Ω—Ç–µ—Ö–µ",
        "–≤ –∞–≤—Ç–æ–Ω–æ–º–Ω—ã—Ö —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–Ω—ã—Ö —Å–∏—Å—Ç–µ–º–∞—Ö",
        "–≤ smart city –∏ —É–º–Ω–æ–π –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–µ",
        "–≤ –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—ã—Ö —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è—Ö –∏ EdTech"
    ]
    trend = random.choice(current_trends_2025)
    domain = random.choice(application_domains)
    topic_formats = [
        f"{trend} {domain} –≤ 2025 –≥–æ–¥—É",
        f"–¢–µ–Ω–¥–µ–Ω—Ü–∏–∏ 2025 {trend} {domain}",
        f"{trend} —Ä–µ–≤–æ–ª—é—Ü–∏–æ–Ω–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è {domain} –≤ 2025",
        f"–ö–∞–∫ {trend} —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∏—Ä—É–µ—Ç {domain} –≤ 2025 –≥–æ–¥—É",
        f"–ò–Ω–Ω–æ–≤–∞—Ü–∏–∏ 2025 {trend} –¥–ª—è {domain}",
        f"{trend} –±—É–¥—É—â–µ–µ {domain} –≤ 2025 –≥–æ–¥—É",
        f"–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ {trend} –≤ {domain} 2025"
    ]
    return random.choice(topic_formats)

# ======== –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö —Å—Ç–∞—Ç–µ–π ========
def clean_old_articles(keep_last=3):
    logger.info(f"üßπ –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö —Å—Ç–∞—Ç–µ–π, –æ—Å—Ç–∞–≤–ª—è–µ–º {keep_last} –ø–æ—Å–ª–µ–¥–Ω–∏—Ö...")
    content_dir = "content"
    posts_dir = os.path.join(content_dir, "posts")
    if os.path.exists(posts_dir):
        posts = sorted([f for f in os.listdir(posts_dir) if f.endswith('.md')], reverse=True)
        for post in posts[keep_last:]:
            os.remove(os.path.join(posts_dir, post))
            logger.info(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω —Å—Ç–∞—Ä—ã–π –ø–æ—Å—Ç: {post}")
    else:
        os.makedirs(posts_dir, exist_ok=True)
        with open("content/_index.md", "w", encoding="utf-8") as f:
            f.write("---\ntitle: \"–ì–ª–∞–≤–Ω–∞—è\"\n---")
        with open("content/posts/_index.md", "w", encoding="utf-8") as f:
            f.write("---\ntitle: \"–°—Ç–∞—Ç—å–∏\"\n---")
        logger.info("‚úÖ –°–æ–∑–¥–∞–Ω–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ content")

# ======== –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ ========
def generate_article_content(topic):
    prompt = f"""
–ù–∞–ø–∏—à–∏ —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç—É—é —Å—Ç–∞—Ç—å—é –Ω–∞ —Ç–µ–º—É: '{topic}' –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.
–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:
- –§–æ—Ä–º–∞—Ç Markdown
- 400-600 —Å–ª–æ–≤
- –°—Ç—Ä—É–∫—Ç—É—Ä–∞: –≤–≤–µ–¥–µ–Ω–∏–µ, –æ—Å–Ω–æ–≤–Ω—ã–µ —Ä–∞–∑–¥–µ–ª—ã, –∑–∞–∫–ª—é—á–µ–Ω–∏–µ
- –ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π —Å—Ç–∏–ª—å
- –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã –∏ –∫–µ–π—Å—ã
"""
    logger.info(f"üìù –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ OpenAI GPT")
    if not OPENAI_KEY:
        return generate_fallback_content(topic), "fallback-generator"
    try:
        response = openai.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7,
            max_tokens=2000
        )
        content = response.choices[0].message.content.strip()
        return content, "OpenAI GPT-4"
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞: {e}")
        return generate_fallback_content(topic), "fallback-generator"

def generate_fallback_content(topic):
    sections = [
        f"# {topic}",
        "",
        "## –í–≤–µ–¥–µ–Ω–∏–µ",
        f"–¢–µ–º–∞ '{topic}' —Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è increasingly important –≤ 2025 –≥–æ–¥—É.",
        "",
        "## –û—Å–Ω–æ–≤–Ω—ã–µ —Ç–µ–Ω–¥–µ–Ω—Ü–∏–∏",
        "- –ê–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏",
        "- –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è AI –≤ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ workflow",
        "- –£–ª—É—á—à–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ –∏ —Å–∫–æ—Ä–æ—Å—Ç–∏ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏",
        "",
        "## –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ",
        "–ö–æ–º–ø–∞–Ω–∏–∏ –≤–Ω–µ–¥—Ä—è—é—Ç AI —Ä–µ—à–µ–Ω–∏—è –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ —Å–≤–æ–∏—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ–≤.",
        "",
        "## –ó–∞–∫–ª—é—á–µ–Ω–∏–µ",
        "–ë—É–¥—É—â–µ–µ –≤—ã–≥–ª—è–¥–∏—Ç promising —Å —Ä–∞–∑–≤–∏—Ç–∏–µ–º AI —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π.",
        "",
        "*–°—Ç–∞—Ç—å—è —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏*"
    ]
    return "\n".join(sections)

# ======== –ü–µ—Ä–µ–±–æ—Ä —Å–µ—Ä–≤–∏—Å–æ–≤ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π ========
def generate_article_image(topic):
    prompt = f"{topic}, digital art, futuristic, AI technology, 4k, high quality, trending"

    # –ü—É—Ç—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
    os.makedirs("assets/images/posts", exist_ok=True)
    filename = f"assets/images/posts/{generate_slug(topic)}.png"

    # 1. Craiyon (–±–µ–∑ –∫–ª—é—á–∞)
    try:
        logger.info("üé® –ü—Ä–æ–±—É–µ–º Craiyon...")
        resp = requests.post("https://api.craiyon.com/v3", json={"prompt": prompt}, timeout=60)
        if resp.status_code == 200 and "images" in resp.json():
            img_url = resp.json()["images"][0]
            img_data = requests.get(img_url, timeout=30).content
            with open(filename, "wb") as f:
                f.write(img_data)
            logger.info(f"‚úÖ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ–ª—É—á–µ–Ω–æ –∏–∑ Craiyon: {filename}")
            return filename
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è Craiyon –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª: {e}")

    # 2. Unsplash (–∫–ª—é—á –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω)
    if UNSPLASH_KEY:
        try:
            logger.info("üé® –ü—Ä–æ–±—É–µ–º Unsplash...")
            url = f"https://api.unsplash.com/photos/random?query={topic}&client_id={UNSPLASH_KEY}"
            resp = requests.get(url, timeout=30)
            if resp.status_code == 200 and "urls" in resp.json():
                img_url = resp.json()["urls"]["regular"]
                img_data = requests.get(img_url, timeout=30).content
                with open(filename, "wb") as f:
                    f.write(img_data)
                logger.info(f"‚úÖ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ–ª—É—á–µ–Ω–æ –∏–∑ Unsplash: {filename}")
                return filename
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Unsplash –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª: {e}")

    # 3. Pixabay (–∫–ª—é—á –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω)
    if PIXABAY_KEY:
        try:
            logger.info("üé® –ü—Ä–æ–±—É–µ–º Pixabay...")
            url = f"https://pixabay.com/api/?key={PIXABAY_KEY}&q={topic}&image_type=photo"
            resp = requests.get(url, timeout=30)
            data = resp.json()
            if "hits" in data and len(data["hits"]) > 0:
                img_url = data["hits"][0]["largeImageURL"]
                img_data = requests.get(img_url, timeout=30).content
                with open(filename, "wb") as f:
                    f.write(img_data)
                logger.info(f"‚úÖ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ–ª—É—á–µ–Ω–æ –∏–∑ Pixabay: {filename}")
                return filename
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Pixabay –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª: {e}")

    # 4. DeepAI (–∫–ª—é—á –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω)
    if DEEPAI_KEY:
        try:
            logger.info("üé® –ü—Ä–æ–±—É–µ–º DeepAI...")
            url = "https://api.deepai.org/api/text2img"
            resp = requests.post(
                url,
                data={"text": prompt},
                headers={"api-key": DEEPAI_KEY},
                timeout=60
            )
            if resp.status_code == 200 and "output_url" in resp.json():
                img_url = resp.json()["output_url"]
                img_data = requests.get(img_url, timeout=30).content
                with open(filename, "wb") as f:
                    f.write(img_data)
                logger.info(f"‚úÖ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ–ª—É—á–µ–Ω–æ –∏–∑ DeepAI: {filename}")
                return filename
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è DeepAI –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª: {e}")

    # 5. OpenAI DALL¬∑E (–µ—Å–ª–∏ –µ—Å—Ç—å –∫–ª—é—á)
    if OPENAI_KEY:
        try:
            logger.info("üé® –ü—Ä–æ–±—É–µ–º OpenAI DALL¬∑E...")
            response = openai.images.generate(
                model="gpt-image-1",
                prompt=prompt,
                size="1024x1024"
            )
            image_base64 = response.data[0].b64_json
            image_bytes = base64.b64decode(image_base64)
            with open(filename, "wb") as f:
                f.write(image_bytes)
            logger.info(f"‚úÖ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ–ª—É—á–µ–Ω–æ —á–µ—Ä–µ–∑ DALL¬∑E: {filename}")
            return filename
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è DALL¬∑E –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª: {e}")

    # 6. –ï—Å–ª–∏ –≤—Å—ë —Å–ª–æ–º–∞–ª–æ—Å—å ‚Üí –¥–µ–ª–∞–µ–º –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä
    return generate_enhanced_placeholder(topic)

# ======== –ü–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä ========
def generate_enhanced_placeholder(topic):
    filename = f"assets/images/posts/{generate_slug(topic)}.png"
    width, height = 800, 400
    img = Image.new('RGB', (width, height), color='#0f172a')
    draw = ImageDraw.Draw(img)
    for i in range(height):
        r = int(15 + (i/height)*40)
        g = int(23 + (i/height)*60)
        b = int(42 + (i/height)*100)
        draw.line([(0, i), (width, i)], fill=(r, g, b))
    wrapped_text = textwrap.fill(topic, width=35)
    try:
        font = ImageFont.truetype("Arial.ttf", 22)
    except:
        font = ImageFont.load_default()
    bbox = draw.textbbox((0, 0), wrapped_text, font=font)
    text_width = bbox[2] - bbox[0]
    text_height = bbox[3] - bbox[1]
    x = (width - text_width) / 2
    y = (height - text_height) / 2
    draw.text((x+3, y+3), wrapped_text, font=font, fill="#000000")
    draw.text((x, y), wrapped_text, font=font, fill="#ffffff")
    img.save(filename)
    logger.info(f"üíæ Placeholder –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {filename}")
    return filename

# ======== –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ ========
def generate_slug(text):
    slug = re.sub(r'[^\w\s-]', '', text).strip().lower()
    slug = re.sub(r'[\s_-]+', '-', slug)
    return slug

def generate_frontmatter(title, content, model_used, image_filename):
    frontmatter = f"""---
title: "{title}"
date: {datetime.now(timezone.utc).strftime('%Y-%m-%d')}
image: "{image_filename}"
model: "{model_used}"
---
{content}
"""
    return frontmatter

# ======== –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—Ç–∞—Ç—å–∏ ========
def generate_content():
    logger.info("üöÄ –ó–∞–ø—É—Å–∫ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞...")
    clean_old_articles()
    topic = generate_ai_trend_topic()
    logger.info(f"üìù –¢–µ–º–∞: {topic}")
    image_filename = generate_article_image(topic)
    content, model_used = generate_article_content(topic)
    slug = generate_slug(topic)
    filename = f"content/posts/{datetime.now(timezone.utc).strftime('%Y-%m-%d')}-{slug}.md"
    frontmatter = generate_frontmatter(topic, content, model_used, image_filename)
    os.makedirs("content/posts", exist_ok=True)
    with open(filename, 'w', encoding='utf-8') as f:
        f.write(frontmatter)
    logger.info(f"‚úÖ –°—Ç–∞—Ç—å—è —Å–æ–∑–¥–∞–Ω–∞: {filename}")
    return filename

# ======== –ì–ª–∞–≤–Ω–∞—è —Ç–æ—á–∫–∞ ========
if __name__ == "__main__":
    generate_content()
